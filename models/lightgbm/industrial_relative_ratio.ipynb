{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pickle\n",
    "import optuna as optuna\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.inspection import permutation_importance\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CompNo</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>StkIndx</th>\n",
       "      <th>STInt</th>\n",
       "      <th>dtdlevel</th>\n",
       "      <th>dtdtrend</th>\n",
       "      <th>liqnonfinlevel</th>\n",
       "      <th>liqnonfintrend</th>\n",
       "      <th>ni2talevel</th>\n",
       "      <th>...</th>\n",
       "      <th>gross_margin_ratio</th>\n",
       "      <th>operating_profit_margin</th>\n",
       "      <th>ebitda_margin</th>\n",
       "      <th>debt_service_coverage_ratio</th>\n",
       "      <th>interest_coverage_ratio</th>\n",
       "      <th>Rolling_Sortino</th>\n",
       "      <th>macd</th>\n",
       "      <th>macd_h</th>\n",
       "      <th>macd_s</th>\n",
       "      <th>rsi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26661</th>\n",
       "      <td>34285</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.097569</td>\n",
       "      <td>0.011896</td>\n",
       "      <td>-0.146043</td>\n",
       "      <td>0.019790</td>\n",
       "      <td>-0.143775</td>\n",
       "      <td>0.135087</td>\n",
       "      <td>0.002171</td>\n",
       "      <td>...</td>\n",
       "      <td>16.947977</td>\n",
       "      <td>-83.052023</td>\n",
       "      <td>-56.774871</td>\n",
       "      <td>-0.495571</td>\n",
       "      <td>4.743773</td>\n",
       "      <td>-0.105924</td>\n",
       "      <td>-0.124699</td>\n",
       "      <td>-0.070089</td>\n",
       "      <td>-0.054610</td>\n",
       "      <td>39.313984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28323</th>\n",
       "      <td>27012</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.097569</td>\n",
       "      <td>0.011896</td>\n",
       "      <td>4.669174</td>\n",
       "      <td>1.296638</td>\n",
       "      <td>0.049928</td>\n",
       "      <td>-0.061520</td>\n",
       "      <td>0.006169</td>\n",
       "      <td>...</td>\n",
       "      <td>25.322690</td>\n",
       "      <td>-58.501388</td>\n",
       "      <td>-55.157066</td>\n",
       "      <td>-0.460564</td>\n",
       "      <td>5.182841</td>\n",
       "      <td>0.421720</td>\n",
       "      <td>0.746325</td>\n",
       "      <td>0.434003</td>\n",
       "      <td>0.312323</td>\n",
       "      <td>73.233696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28324</th>\n",
       "      <td>41558</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.097569</td>\n",
       "      <td>0.011896</td>\n",
       "      <td>2.619373</td>\n",
       "      <td>0.604174</td>\n",
       "      <td>0.387817</td>\n",
       "      <td>0.336426</td>\n",
       "      <td>0.008513</td>\n",
       "      <td>...</td>\n",
       "      <td>86.464646</td>\n",
       "      <td>-0.570644</td>\n",
       "      <td>3.606774</td>\n",
       "      <td>-0.015032</td>\n",
       "      <td>1.138614</td>\n",
       "      <td>-0.676048</td>\n",
       "      <td>-0.917783</td>\n",
       "      <td>-0.331746</td>\n",
       "      <td>-0.586037</td>\n",
       "      <td>14.925373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28325</th>\n",
       "      <td>28960</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.097569</td>\n",
       "      <td>0.011896</td>\n",
       "      <td>0.169095</td>\n",
       "      <td>-0.026455</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000645</td>\n",
       "      <td>...</td>\n",
       "      <td>51.539837</td>\n",
       "      <td>-27.176966</td>\n",
       "      <td>-14.519993</td>\n",
       "      <td>-0.032901</td>\n",
       "      <td>3.242347</td>\n",
       "      <td>0.022830</td>\n",
       "      <td>-0.025289</td>\n",
       "      <td>-0.036679</td>\n",
       "      <td>0.011390</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28326</th>\n",
       "      <td>28960</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.097569</td>\n",
       "      <td>0.011896</td>\n",
       "      <td>0.169095</td>\n",
       "      <td>-0.026455</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000645</td>\n",
       "      <td>...</td>\n",
       "      <td>51.539837</td>\n",
       "      <td>-27.176966</td>\n",
       "      <td>-14.519993</td>\n",
       "      <td>-0.032901</td>\n",
       "      <td>3.242347</td>\n",
       "      <td>0.022830</td>\n",
       "      <td>-0.025289</td>\n",
       "      <td>-0.036679</td>\n",
       "      <td>0.011390</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       CompNo    year  month   StkIndx     STInt  dtdlevel  dtdtrend  \\\n",
       "26661   34285  2000.0     12 -0.097569  0.011896 -0.146043  0.019790   \n",
       "28323   27012  2000.0     12 -0.097569  0.011896  4.669174  1.296638   \n",
       "28324   41558  2000.0     12 -0.097569  0.011896  2.619373  0.604174   \n",
       "28325   28960  2000.0     12 -0.097569  0.011896  0.169095 -0.026455   \n",
       "28326   28960  2000.0     12 -0.097569  0.011896  0.169095 -0.026455   \n",
       "\n",
       "       liqnonfinlevel  liqnonfintrend  ni2talevel  ...  gross_margin_ratio  \\\n",
       "26661       -0.143775        0.135087    0.002171  ...           16.947977   \n",
       "28323        0.049928       -0.061520    0.006169  ...           25.322690   \n",
       "28324        0.387817        0.336426    0.008513  ...           86.464646   \n",
       "28325        0.000000        0.000000    0.000645  ...           51.539837   \n",
       "28326        0.000000        0.000000    0.000645  ...           51.539837   \n",
       "\n",
       "       operating_profit_margin  ebitda_margin  debt_service_coverage_ratio  \\\n",
       "26661               -83.052023     -56.774871                    -0.495571   \n",
       "28323               -58.501388     -55.157066                    -0.460564   \n",
       "28324                -0.570644       3.606774                    -0.015032   \n",
       "28325               -27.176966     -14.519993                    -0.032901   \n",
       "28326               -27.176966     -14.519993                    -0.032901   \n",
       "\n",
       "       interest_coverage_ratio  Rolling_Sortino      macd    macd_h    macd_s  \\\n",
       "26661                 4.743773        -0.105924 -0.124699 -0.070089 -0.054610   \n",
       "28323                 5.182841         0.421720  0.746325  0.434003  0.312323   \n",
       "28324                 1.138614        -0.676048 -0.917783 -0.331746 -0.586037   \n",
       "28325                 3.242347         0.022830 -0.025289 -0.036679  0.011390   \n",
       "28326                 3.242347         0.022830 -0.025289 -0.036679  0.011390   \n",
       "\n",
       "             rsi  \n",
       "26661  39.313984  \n",
       "28323  73.233696  \n",
       "28324  14.925373  \n",
       "28325  50.000000  \n",
       "28326  50.000000  \n",
       "\n",
       "[5 rows x 57 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_pickle('../../data_preprocessing/cri_compustat_v8_yfinance.pkl')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(579815, 57)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompNo                         0\n",
       "quick_ratio                    0\n",
       "net_working_capital            0\n",
       "debt_ratio                     0\n",
       "debt_to_equity_ratio           0\n",
       "equity_ratio                   0\n",
       "cashflow_to_debt_ratio         0\n",
       "net_profit_margin              0\n",
       "return_on_assets               0\n",
       "asset_turnover                 0\n",
       "inventory_turnover             0\n",
       "days_in_inventory              0\n",
       "receivables_turnover           0\n",
       "day_sales_outstanding          0\n",
       "working_capital_turnover       0\n",
       "price_to_earnings              0\n",
       "dividend_payout_ratio          0\n",
       "retention_ratio                0\n",
       "gross_margin_ratio             0\n",
       "operating_profit_margin        0\n",
       "ebitda_margin                  0\n",
       "debt_service_coverage_ratio    0\n",
       "interest_coverage_ratio        0\n",
       "Rolling_Sortino                0\n",
       "macd                           0\n",
       "macd_h                         0\n",
       "macd_s                         0\n",
       "cash_ratio                     0\n",
       "current_ratio                  0\n",
       "year                           0\n",
       "tic                            0\n",
       "month                          0\n",
       "StkIndx                        0\n",
       "STInt                          0\n",
       "dtdlevel                       0\n",
       "dtdtrend                       0\n",
       "liqnonfinlevel                 0\n",
       "liqnonfintrend                 0\n",
       "ni2talevel                     0\n",
       "ni2tatrend                     0\n",
       "sizelevel                      0\n",
       "sizetrend                      0\n",
       "m2b                            0\n",
       "sigma                          0\n",
       "liqfinlevel                    0\n",
       "lqfintrend                     0\n",
       "DTDmedianFin                   0\n",
       "DTDmedianNonFin                0\n",
       "dummy297fin                    0\n",
       "Default                        0\n",
       "day                            0\n",
       "date                           0\n",
       "StartDate                      0\n",
       "EventDate                      0\n",
       "Duration                       0\n",
       "gvkey                          0\n",
       "rsi                            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CompNo', 'year', 'month', 'StkIndx', 'STInt', 'dtdlevel', 'dtdtrend',\n",
       "       'liqnonfinlevel', 'liqnonfintrend', 'ni2talevel', 'ni2tatrend',\n",
       "       'sizelevel', 'sizetrend', 'm2b', 'sigma', 'liqfinlevel', 'lqfintrend',\n",
       "       'DTDmedianFin', 'DTDmedianNonFin', 'dummy297fin', 'Default', 'day',\n",
       "       'date', 'StartDate', 'EventDate', 'Duration', 'gvkey', 'tic',\n",
       "       'current_ratio', 'quick_ratio', 'cash_ratio', 'net_working_capital',\n",
       "       'debt_ratio', 'debt_to_equity_ratio', 'equity_ratio',\n",
       "       'cashflow_to_debt_ratio', 'net_profit_margin', 'return_on_assets',\n",
       "       'asset_turnover', 'inventory_turnover', 'days_in_inventory',\n",
       "       'receivables_turnover', 'day_sales_outstanding',\n",
       "       'working_capital_turnover', 'price_to_earnings',\n",
       "       'dividend_payout_ratio', 'retention_ratio', 'gross_margin_ratio',\n",
       "       'operating_profit_margin', 'ebitda_margin',\n",
       "       'debt_service_coverage_ratio', 'interest_coverage_ratio',\n",
       "       'Rolling_Sortino', 'macd', 'macd_h', 'macd_s', 'rsi'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StkIndx</th>\n",
       "      <th>STInt</th>\n",
       "      <th>dtdlevel</th>\n",
       "      <th>dtdtrend</th>\n",
       "      <th>liqnonfinlevel</th>\n",
       "      <th>liqnonfintrend</th>\n",
       "      <th>ni2talevel</th>\n",
       "      <th>ni2tatrend</th>\n",
       "      <th>sizelevel</th>\n",
       "      <th>sizetrend</th>\n",
       "      <th>...</th>\n",
       "      <th>gross_margin_ratio</th>\n",
       "      <th>operating_profit_margin</th>\n",
       "      <th>ebitda_margin</th>\n",
       "      <th>debt_service_coverage_ratio</th>\n",
       "      <th>interest_coverage_ratio</th>\n",
       "      <th>Rolling_Sortino</th>\n",
       "      <th>macd</th>\n",
       "      <th>macd_h</th>\n",
       "      <th>macd_s</th>\n",
       "      <th>rsi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26661</th>\n",
       "      <td>-0.097569</td>\n",
       "      <td>0.011896</td>\n",
       "      <td>-0.146043</td>\n",
       "      <td>0.019790</td>\n",
       "      <td>-0.143775</td>\n",
       "      <td>0.135087</td>\n",
       "      <td>0.002171</td>\n",
       "      <td>0.008310</td>\n",
       "      <td>-2.161520</td>\n",
       "      <td>0.244958</td>\n",
       "      <td>...</td>\n",
       "      <td>16.947977</td>\n",
       "      <td>-83.052023</td>\n",
       "      <td>-56.774871</td>\n",
       "      <td>-0.495571</td>\n",
       "      <td>4.743773</td>\n",
       "      <td>-0.105924</td>\n",
       "      <td>-0.124699</td>\n",
       "      <td>-0.070089</td>\n",
       "      <td>-0.054610</td>\n",
       "      <td>39.313984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28323</th>\n",
       "      <td>-0.097569</td>\n",
       "      <td>0.011896</td>\n",
       "      <td>4.669174</td>\n",
       "      <td>1.296638</td>\n",
       "      <td>0.049928</td>\n",
       "      <td>-0.061520</td>\n",
       "      <td>0.006169</td>\n",
       "      <td>-0.000124</td>\n",
       "      <td>1.570984</td>\n",
       "      <td>0.300040</td>\n",
       "      <td>...</td>\n",
       "      <td>25.322690</td>\n",
       "      <td>-58.501388</td>\n",
       "      <td>-55.157066</td>\n",
       "      <td>-0.460564</td>\n",
       "      <td>5.182841</td>\n",
       "      <td>0.421720</td>\n",
       "      <td>0.746325</td>\n",
       "      <td>0.434003</td>\n",
       "      <td>0.312323</td>\n",
       "      <td>73.233696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28324</th>\n",
       "      <td>-0.097569</td>\n",
       "      <td>0.011896</td>\n",
       "      <td>2.619373</td>\n",
       "      <td>0.604174</td>\n",
       "      <td>0.387817</td>\n",
       "      <td>0.336426</td>\n",
       "      <td>0.008513</td>\n",
       "      <td>-0.000050</td>\n",
       "      <td>1.371984</td>\n",
       "      <td>-0.219227</td>\n",
       "      <td>...</td>\n",
       "      <td>86.464646</td>\n",
       "      <td>-0.570644</td>\n",
       "      <td>3.606774</td>\n",
       "      <td>-0.015032</td>\n",
       "      <td>1.138614</td>\n",
       "      <td>-0.676048</td>\n",
       "      <td>-0.917783</td>\n",
       "      <td>-0.331746</td>\n",
       "      <td>-0.586037</td>\n",
       "      <td>14.925373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28325</th>\n",
       "      <td>-0.097569</td>\n",
       "      <td>0.011896</td>\n",
       "      <td>0.169095</td>\n",
       "      <td>-0.026455</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000645</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>-1.820189</td>\n",
       "      <td>-0.000369</td>\n",
       "      <td>...</td>\n",
       "      <td>51.539837</td>\n",
       "      <td>-27.176966</td>\n",
       "      <td>-14.519993</td>\n",
       "      <td>-0.032901</td>\n",
       "      <td>3.242347</td>\n",
       "      <td>0.022830</td>\n",
       "      <td>-0.025289</td>\n",
       "      <td>-0.036679</td>\n",
       "      <td>0.011390</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28326</th>\n",
       "      <td>-0.097569</td>\n",
       "      <td>0.011896</td>\n",
       "      <td>0.169095</td>\n",
       "      <td>-0.026455</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000645</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>-1.820189</td>\n",
       "      <td>-0.000369</td>\n",
       "      <td>...</td>\n",
       "      <td>51.539837</td>\n",
       "      <td>-27.176966</td>\n",
       "      <td>-14.519993</td>\n",
       "      <td>-0.032901</td>\n",
       "      <td>3.242347</td>\n",
       "      <td>0.022830</td>\n",
       "      <td>-0.025289</td>\n",
       "      <td>-0.036679</td>\n",
       "      <td>0.011390</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613886</th>\n",
       "      <td>-0.120300</td>\n",
       "      <td>-0.010290</td>\n",
       "      <td>5.645101</td>\n",
       "      <td>0.280356</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003193</td>\n",
       "      <td>-0.001147</td>\n",
       "      <td>1.973981</td>\n",
       "      <td>0.317684</td>\n",
       "      <td>...</td>\n",
       "      <td>61.284040</td>\n",
       "      <td>16.386287</td>\n",
       "      <td>21.482218</td>\n",
       "      <td>0.007420</td>\n",
       "      <td>1.563234</td>\n",
       "      <td>-0.271997</td>\n",
       "      <td>-0.033162</td>\n",
       "      <td>-0.041029</td>\n",
       "      <td>0.007867</td>\n",
       "      <td>43.412176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613885</th>\n",
       "      <td>0.011539</td>\n",
       "      <td>0.009881</td>\n",
       "      <td>4.451980</td>\n",
       "      <td>-0.293586</td>\n",
       "      <td>1.300011</td>\n",
       "      <td>0.586387</td>\n",
       "      <td>-0.017127</td>\n",
       "      <td>0.035331</td>\n",
       "      <td>1.895036</td>\n",
       "      <td>0.114872</td>\n",
       "      <td>...</td>\n",
       "      <td>34.754251</td>\n",
       "      <td>-30.491498</td>\n",
       "      <td>-28.666753</td>\n",
       "      <td>-0.538759</td>\n",
       "      <td>10.052205</td>\n",
       "      <td>0.106019</td>\n",
       "      <td>-5.516866</td>\n",
       "      <td>-1.133378</td>\n",
       "      <td>-4.383488</td>\n",
       "      <td>46.610352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613884</th>\n",
       "      <td>0.011539</td>\n",
       "      <td>0.009881</td>\n",
       "      <td>5.082761</td>\n",
       "      <td>-0.707860</td>\n",
       "      <td>-0.052495</td>\n",
       "      <td>-0.047746</td>\n",
       "      <td>0.007015</td>\n",
       "      <td>0.001609</td>\n",
       "      <td>1.612279</td>\n",
       "      <td>-0.076518</td>\n",
       "      <td>...</td>\n",
       "      <td>19.819979</td>\n",
       "      <td>-69.958391</td>\n",
       "      <td>-67.165292</td>\n",
       "      <td>-0.362695</td>\n",
       "      <td>5.971954</td>\n",
       "      <td>-0.081162</td>\n",
       "      <td>-4.053199</td>\n",
       "      <td>-2.719688</td>\n",
       "      <td>-1.333511</td>\n",
       "      <td>40.187935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613897</th>\n",
       "      <td>-0.120300</td>\n",
       "      <td>-0.010290</td>\n",
       "      <td>4.231041</td>\n",
       "      <td>-0.429897</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001674</td>\n",
       "      <td>-0.002132</td>\n",
       "      <td>4.066935</td>\n",
       "      <td>0.089546</td>\n",
       "      <td>...</td>\n",
       "      <td>57.518523</td>\n",
       "      <td>10.705924</td>\n",
       "      <td>21.482218</td>\n",
       "      <td>0.003456</td>\n",
       "      <td>1.563234</td>\n",
       "      <td>-0.692579</td>\n",
       "      <td>-4.099552</td>\n",
       "      <td>-0.949074</td>\n",
       "      <td>-3.150478</td>\n",
       "      <td>26.876560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615245</th>\n",
       "      <td>0.011539</td>\n",
       "      <td>0.009881</td>\n",
       "      <td>10.035608</td>\n",
       "      <td>1.044848</td>\n",
       "      <td>0.144421</td>\n",
       "      <td>0.117867</td>\n",
       "      <td>0.010069</td>\n",
       "      <td>-0.001637</td>\n",
       "      <td>6.386785</td>\n",
       "      <td>0.331103</td>\n",
       "      <td>...</td>\n",
       "      <td>81.833333</td>\n",
       "      <td>10.012931</td>\n",
       "      <td>15.218391</td>\n",
       "      <td>0.036905</td>\n",
       "      <td>19.078794</td>\n",
       "      <td>0.510868</td>\n",
       "      <td>46.540101</td>\n",
       "      <td>3.995748</td>\n",
       "      <td>42.544353</td>\n",
       "      <td>79.370140</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>579815 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         StkIndx     STInt   dtdlevel  dtdtrend  liqnonfinlevel  \\\n",
       "26661  -0.097569  0.011896  -0.146043  0.019790       -0.143775   \n",
       "28323  -0.097569  0.011896   4.669174  1.296638        0.049928   \n",
       "28324  -0.097569  0.011896   2.619373  0.604174        0.387817   \n",
       "28325  -0.097569  0.011896   0.169095 -0.026455        0.000000   \n",
       "28326  -0.097569  0.011896   0.169095 -0.026455        0.000000   \n",
       "...          ...       ...        ...       ...             ...   \n",
       "613886 -0.120300 -0.010290   5.645101  0.280356        0.000000   \n",
       "613885  0.011539  0.009881   4.451980 -0.293586        1.300011   \n",
       "613884  0.011539  0.009881   5.082761 -0.707860       -0.052495   \n",
       "613897 -0.120300 -0.010290   4.231041 -0.429897        0.000000   \n",
       "615245  0.011539  0.009881  10.035608  1.044848        0.144421   \n",
       "\n",
       "        liqnonfintrend  ni2talevel  ni2tatrend  sizelevel  sizetrend  ...  \\\n",
       "26661         0.135087    0.002171    0.008310  -2.161520   0.244958  ...   \n",
       "28323        -0.061520    0.006169   -0.000124   1.570984   0.300040  ...   \n",
       "28324         0.336426    0.008513   -0.000050   1.371984  -0.219227  ...   \n",
       "28325         0.000000    0.000645    0.000020  -1.820189  -0.000369  ...   \n",
       "28326         0.000000    0.000645    0.000020  -1.820189  -0.000369  ...   \n",
       "...                ...         ...         ...        ...        ...  ...   \n",
       "613886        0.000000    0.003193   -0.001147   1.973981   0.317684  ...   \n",
       "613885        0.586387   -0.017127    0.035331   1.895036   0.114872  ...   \n",
       "613884       -0.047746    0.007015    0.001609   1.612279  -0.076518  ...   \n",
       "613897        0.000000    0.001674   -0.002132   4.066935   0.089546  ...   \n",
       "615245        0.117867    0.010069   -0.001637   6.386785   0.331103  ...   \n",
       "\n",
       "        gross_margin_ratio  operating_profit_margin  ebitda_margin  \\\n",
       "26661            16.947977               -83.052023     -56.774871   \n",
       "28323            25.322690               -58.501388     -55.157066   \n",
       "28324            86.464646                -0.570644       3.606774   \n",
       "28325            51.539837               -27.176966     -14.519993   \n",
       "28326            51.539837               -27.176966     -14.519993   \n",
       "...                    ...                      ...            ...   \n",
       "613886           61.284040                16.386287      21.482218   \n",
       "613885           34.754251               -30.491498     -28.666753   \n",
       "613884           19.819979               -69.958391     -67.165292   \n",
       "613897           57.518523                10.705924      21.482218   \n",
       "615245           81.833333                10.012931      15.218391   \n",
       "\n",
       "        debt_service_coverage_ratio  interest_coverage_ratio  Rolling_Sortino  \\\n",
       "26661                     -0.495571                 4.743773        -0.105924   \n",
       "28323                     -0.460564                 5.182841         0.421720   \n",
       "28324                     -0.015032                 1.138614        -0.676048   \n",
       "28325                     -0.032901                 3.242347         0.022830   \n",
       "28326                     -0.032901                 3.242347         0.022830   \n",
       "...                             ...                      ...              ...   \n",
       "613886                     0.007420                 1.563234        -0.271997   \n",
       "613885                    -0.538759                10.052205         0.106019   \n",
       "613884                    -0.362695                 5.971954        -0.081162   \n",
       "613897                     0.003456                 1.563234        -0.692579   \n",
       "615245                     0.036905                19.078794         0.510868   \n",
       "\n",
       "             macd    macd_h     macd_s        rsi  \n",
       "26661   -0.124699 -0.070089  -0.054610  39.313984  \n",
       "28323    0.746325  0.434003   0.312323  73.233696  \n",
       "28324   -0.917783 -0.331746  -0.586037  14.925373  \n",
       "28325   -0.025289 -0.036679   0.011390  50.000000  \n",
       "28326   -0.025289 -0.036679   0.011390  50.000000  \n",
       "...           ...       ...        ...        ...  \n",
       "613886  -0.033162 -0.041029   0.007867  43.412176  \n",
       "613885  -5.516866 -1.133378  -4.383488  46.610352  \n",
       "613884  -4.053199 -2.719688  -1.333511  40.187935  \n",
       "613897  -4.099552 -0.949074  -3.150478  26.876560  \n",
       "615245  46.540101  3.995748  42.544353  79.370140  \n",
       "\n",
       "[579815 rows x 47 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop columns\n",
    "df = data.drop(columns = ['CompNo', 'year', 'month', 'dummy297fin', 'day', 'date', 'StartDate', 'EventDate', 'gvkey', 'tic'])\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "top features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tic</th>\n",
       "      <th>sic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AIR</td>\n",
       "      <td>5080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>4165A</td>\n",
       "      <td>3743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>ADCT.1</td>\n",
       "      <td>3661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>AFAP</td>\n",
       "      <td>7380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>IWKS</td>\n",
       "      <td>3844</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        tic   sic\n",
       "0       AIR  5080\n",
       "94    4165A  3743\n",
       "112  ADCT.1  3661\n",
       "156    AFAP  7380\n",
       "240    IWKS  3844"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load compna to get sic\n",
    "compna = pd.read_pickle('sic_map.pkl')\n",
    "compna.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['CompNo', 'year', 'month', 'StkIndx', 'STInt', 'dtdlevel', 'dtdtrend',\n",
       "       'liqnonfinlevel', 'liqnonfintrend', 'ni2talevel', 'ni2tatrend',\n",
       "       'sizelevel', 'sizetrend', 'm2b', 'sigma', 'liqfinlevel', 'lqfintrend',\n",
       "       'DTDmedianFin', 'DTDmedianNonFin', 'dummy297fin', 'Default', 'day',\n",
       "       'date', 'StartDate', 'EventDate', 'Duration', 'gvkey', 'tic',\n",
       "       'current_ratio', 'quick_ratio', 'cash_ratio', 'net_working_capital',\n",
       "       'debt_ratio', 'debt_to_equity_ratio', 'equity_ratio',\n",
       "       'cashflow_to_debt_ratio', 'net_profit_margin', 'return_on_assets',\n",
       "       'asset_turnover', 'inventory_turnover', 'days_in_inventory',\n",
       "       'receivables_turnover', 'day_sales_outstanding',\n",
       "       'working_capital_turnover', 'price_to_earnings',\n",
       "       'dividend_payout_ratio', 'retention_ratio', 'gross_margin_ratio',\n",
       "       'operating_profit_margin', 'ebitda_margin',\n",
       "       'debt_service_coverage_ratio', 'interest_coverage_ratio',\n",
       "       'Rolling_Sortino', 'macd', 'macd_h', 'macd_s', 'rsi'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create tic sic mapping\n",
    "sic_map = compna[['tic', 'sic']]\n",
    "sic_map= sic_map.drop_duplicates(subset=['tic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tic</th>\n",
       "      <th>sic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AIR</td>\n",
       "      <td>5080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>4165A</td>\n",
       "      <td>3743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>ADCT.1</td>\n",
       "      <td>3661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>AFAP</td>\n",
       "      <td>7380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>IWKS</td>\n",
       "      <td>3844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1075517</th>\n",
       "      <td>IVCGF</td>\n",
       "      <td>3711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1075535</th>\n",
       "      <td>DTRUY</td>\n",
       "      <td>3713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1075551</th>\n",
       "      <td>HLN</td>\n",
       "      <td>2834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1075561</th>\n",
       "      <td>ACLLY</td>\n",
       "      <td>3621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1075569</th>\n",
       "      <td>BEMB</td>\n",
       "      <td>6722</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30212 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            tic   sic\n",
       "0           AIR  5080\n",
       "94        4165A  3743\n",
       "112      ADCT.1  3661\n",
       "156        AFAP  7380\n",
       "240        IWKS  3844\n",
       "...         ...   ...\n",
       "1075517   IVCGF  3711\n",
       "1075535   DTRUY  3713\n",
       "1075551     HLN  2834\n",
       "1075561   ACLLY  3621\n",
       "1075569    BEMB  6722\n",
       "\n",
       "[30212 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sic_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CompNo</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>StkIndx</th>\n",
       "      <th>STInt</th>\n",
       "      <th>dtdlevel</th>\n",
       "      <th>dtdtrend</th>\n",
       "      <th>liqnonfinlevel</th>\n",
       "      <th>liqnonfintrend</th>\n",
       "      <th>ni2talevel</th>\n",
       "      <th>...</th>\n",
       "      <th>operating_profit_margin</th>\n",
       "      <th>ebitda_margin</th>\n",
       "      <th>debt_service_coverage_ratio</th>\n",
       "      <th>interest_coverage_ratio</th>\n",
       "      <th>Rolling_Sortino</th>\n",
       "      <th>macd</th>\n",
       "      <th>macd_h</th>\n",
       "      <th>macd_s</th>\n",
       "      <th>rsi</th>\n",
       "      <th>sic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26661</th>\n",
       "      <td>34285</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.097569</td>\n",
       "      <td>0.011896</td>\n",
       "      <td>-0.146043</td>\n",
       "      <td>0.019790</td>\n",
       "      <td>-0.143775</td>\n",
       "      <td>0.135087</td>\n",
       "      <td>0.002171</td>\n",
       "      <td>...</td>\n",
       "      <td>-83.052023</td>\n",
       "      <td>-56.774871</td>\n",
       "      <td>-0.495571</td>\n",
       "      <td>4.743773</td>\n",
       "      <td>-0.105924</td>\n",
       "      <td>-0.124699</td>\n",
       "      <td>-0.070089</td>\n",
       "      <td>-0.054610</td>\n",
       "      <td>39.313984</td>\n",
       "      <td>3490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28323</th>\n",
       "      <td>27012</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.097569</td>\n",
       "      <td>0.011896</td>\n",
       "      <td>4.669174</td>\n",
       "      <td>1.296638</td>\n",
       "      <td>0.049928</td>\n",
       "      <td>-0.061520</td>\n",
       "      <td>0.006169</td>\n",
       "      <td>...</td>\n",
       "      <td>-58.501388</td>\n",
       "      <td>-55.157066</td>\n",
       "      <td>-0.460564</td>\n",
       "      <td>5.182841</td>\n",
       "      <td>0.421720</td>\n",
       "      <td>0.746325</td>\n",
       "      <td>0.434003</td>\n",
       "      <td>0.312323</td>\n",
       "      <td>73.233696</td>\n",
       "      <td>3480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28324</th>\n",
       "      <td>41558</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.097569</td>\n",
       "      <td>0.011896</td>\n",
       "      <td>2.619373</td>\n",
       "      <td>0.604174</td>\n",
       "      <td>0.387817</td>\n",
       "      <td>0.336426</td>\n",
       "      <td>0.008513</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.570644</td>\n",
       "      <td>3.606774</td>\n",
       "      <td>-0.015032</td>\n",
       "      <td>1.138614</td>\n",
       "      <td>-0.676048</td>\n",
       "      <td>-0.917783</td>\n",
       "      <td>-0.331746</td>\n",
       "      <td>-0.586037</td>\n",
       "      <td>14.925373</td>\n",
       "      <td>2844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28325</th>\n",
       "      <td>28960</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.097569</td>\n",
       "      <td>0.011896</td>\n",
       "      <td>0.169095</td>\n",
       "      <td>-0.026455</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000645</td>\n",
       "      <td>...</td>\n",
       "      <td>-27.176966</td>\n",
       "      <td>-14.519993</td>\n",
       "      <td>-0.032901</td>\n",
       "      <td>3.242347</td>\n",
       "      <td>0.022830</td>\n",
       "      <td>-0.025289</td>\n",
       "      <td>-0.036679</td>\n",
       "      <td>0.011390</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>6020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28326</th>\n",
       "      <td>28960</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.097569</td>\n",
       "      <td>0.011896</td>\n",
       "      <td>0.169095</td>\n",
       "      <td>-0.026455</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000645</td>\n",
       "      <td>...</td>\n",
       "      <td>-27.176966</td>\n",
       "      <td>-14.519993</td>\n",
       "      <td>-0.032901</td>\n",
       "      <td>3.242347</td>\n",
       "      <td>0.022830</td>\n",
       "      <td>-0.025289</td>\n",
       "      <td>-0.036679</td>\n",
       "      <td>0.011390</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>6020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613886</th>\n",
       "      <td>53941</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.120300</td>\n",
       "      <td>-0.010290</td>\n",
       "      <td>5.645101</td>\n",
       "      <td>0.280356</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003193</td>\n",
       "      <td>...</td>\n",
       "      <td>16.386287</td>\n",
       "      <td>21.482218</td>\n",
       "      <td>0.007420</td>\n",
       "      <td>1.563234</td>\n",
       "      <td>-0.271997</td>\n",
       "      <td>-0.033162</td>\n",
       "      <td>-0.041029</td>\n",
       "      <td>0.007867</td>\n",
       "      <td>43.412176</td>\n",
       "      <td>6798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613885</th>\n",
       "      <td>34205</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.011539</td>\n",
       "      <td>0.009881</td>\n",
       "      <td>4.451980</td>\n",
       "      <td>-0.293586</td>\n",
       "      <td>1.300011</td>\n",
       "      <td>0.586387</td>\n",
       "      <td>-0.017127</td>\n",
       "      <td>...</td>\n",
       "      <td>-30.491498</td>\n",
       "      <td>-28.666753</td>\n",
       "      <td>-0.538759</td>\n",
       "      <td>10.052205</td>\n",
       "      <td>0.106019</td>\n",
       "      <td>-5.516866</td>\n",
       "      <td>-1.133378</td>\n",
       "      <td>-4.383488</td>\n",
       "      <td>46.610352</td>\n",
       "      <td>2836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613884</th>\n",
       "      <td>34191</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.011539</td>\n",
       "      <td>0.009881</td>\n",
       "      <td>5.082761</td>\n",
       "      <td>-0.707860</td>\n",
       "      <td>-0.052495</td>\n",
       "      <td>-0.047746</td>\n",
       "      <td>0.007015</td>\n",
       "      <td>...</td>\n",
       "      <td>-69.958391</td>\n",
       "      <td>-67.165292</td>\n",
       "      <td>-0.362695</td>\n",
       "      <td>5.971954</td>\n",
       "      <td>-0.081162</td>\n",
       "      <td>-4.053199</td>\n",
       "      <td>-2.719688</td>\n",
       "      <td>-1.333511</td>\n",
       "      <td>40.187935</td>\n",
       "      <td>5812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613897</th>\n",
       "      <td>53716</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.120300</td>\n",
       "      <td>-0.010290</td>\n",
       "      <td>4.231041</td>\n",
       "      <td>-0.429897</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001674</td>\n",
       "      <td>...</td>\n",
       "      <td>10.705924</td>\n",
       "      <td>21.482218</td>\n",
       "      <td>0.003456</td>\n",
       "      <td>1.563234</td>\n",
       "      <td>-0.692579</td>\n",
       "      <td>-4.099552</td>\n",
       "      <td>-0.949074</td>\n",
       "      <td>-3.150478</td>\n",
       "      <td>26.876560</td>\n",
       "      <td>6798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615245</th>\n",
       "      <td>27723</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.011539</td>\n",
       "      <td>0.009881</td>\n",
       "      <td>10.035608</td>\n",
       "      <td>1.044848</td>\n",
       "      <td>0.144421</td>\n",
       "      <td>0.117867</td>\n",
       "      <td>0.010069</td>\n",
       "      <td>...</td>\n",
       "      <td>10.012931</td>\n",
       "      <td>15.218391</td>\n",
       "      <td>0.036905</td>\n",
       "      <td>19.078794</td>\n",
       "      <td>0.510868</td>\n",
       "      <td>46.540101</td>\n",
       "      <td>3.995748</td>\n",
       "      <td>42.544353</td>\n",
       "      <td>79.370140</td>\n",
       "      <td>2834</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>579815 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CompNo    year  month   StkIndx     STInt   dtdlevel  dtdtrend  \\\n",
       "26661    34285  2000.0     12 -0.097569  0.011896  -0.146043  0.019790   \n",
       "28323    27012  2000.0     12 -0.097569  0.011896   4.669174  1.296638   \n",
       "28324    41558  2000.0     12 -0.097569  0.011896   2.619373  0.604174   \n",
       "28325    28960  2000.0     12 -0.097569  0.011896   0.169095 -0.026455   \n",
       "28326    28960  2000.0     12 -0.097569  0.011896   0.169095 -0.026455   \n",
       "...        ...     ...    ...       ...       ...        ...       ...   \n",
       "613886   53941  2023.0      5 -0.120300 -0.010290   5.645101  0.280356   \n",
       "613885   34205  2023.0      5  0.011539  0.009881   4.451980 -0.293586   \n",
       "613884   34191  2023.0      5  0.011539  0.009881   5.082761 -0.707860   \n",
       "613897   53716  2023.0      5 -0.120300 -0.010290   4.231041 -0.429897   \n",
       "615245   27723  2023.0      5  0.011539  0.009881  10.035608  1.044848   \n",
       "\n",
       "        liqnonfinlevel  liqnonfintrend  ni2talevel  ...  \\\n",
       "26661        -0.143775        0.135087    0.002171  ...   \n",
       "28323         0.049928       -0.061520    0.006169  ...   \n",
       "28324         0.387817        0.336426    0.008513  ...   \n",
       "28325         0.000000        0.000000    0.000645  ...   \n",
       "28326         0.000000        0.000000    0.000645  ...   \n",
       "...                ...             ...         ...  ...   \n",
       "613886        0.000000        0.000000    0.003193  ...   \n",
       "613885        1.300011        0.586387   -0.017127  ...   \n",
       "613884       -0.052495       -0.047746    0.007015  ...   \n",
       "613897        0.000000        0.000000    0.001674  ...   \n",
       "615245        0.144421        0.117867    0.010069  ...   \n",
       "\n",
       "        operating_profit_margin  ebitda_margin  debt_service_coverage_ratio  \\\n",
       "26661                -83.052023     -56.774871                    -0.495571   \n",
       "28323                -58.501388     -55.157066                    -0.460564   \n",
       "28324                 -0.570644       3.606774                    -0.015032   \n",
       "28325                -27.176966     -14.519993                    -0.032901   \n",
       "28326                -27.176966     -14.519993                    -0.032901   \n",
       "...                         ...            ...                          ...   \n",
       "613886                16.386287      21.482218                     0.007420   \n",
       "613885               -30.491498     -28.666753                    -0.538759   \n",
       "613884               -69.958391     -67.165292                    -0.362695   \n",
       "613897                10.705924      21.482218                     0.003456   \n",
       "615245                10.012931      15.218391                     0.036905   \n",
       "\n",
       "        interest_coverage_ratio  Rolling_Sortino       macd    macd_h  \\\n",
       "26661                  4.743773        -0.105924  -0.124699 -0.070089   \n",
       "28323                  5.182841         0.421720   0.746325  0.434003   \n",
       "28324                  1.138614        -0.676048  -0.917783 -0.331746   \n",
       "28325                  3.242347         0.022830  -0.025289 -0.036679   \n",
       "28326                  3.242347         0.022830  -0.025289 -0.036679   \n",
       "...                         ...              ...        ...       ...   \n",
       "613886                 1.563234        -0.271997  -0.033162 -0.041029   \n",
       "613885                10.052205         0.106019  -5.516866 -1.133378   \n",
       "613884                 5.971954        -0.081162  -4.053199 -2.719688   \n",
       "613897                 1.563234        -0.692579  -4.099552 -0.949074   \n",
       "615245                19.078794         0.510868  46.540101  3.995748   \n",
       "\n",
       "           macd_s        rsi   sic  \n",
       "26661   -0.054610  39.313984  3490  \n",
       "28323    0.312323  73.233696  3480  \n",
       "28324   -0.586037  14.925373  2844  \n",
       "28325    0.011390  50.000000  6020  \n",
       "28326    0.011390  50.000000  6020  \n",
       "...           ...        ...   ...  \n",
       "613886   0.007867  43.412176  6798  \n",
       "613885  -4.383488  46.610352  2836  \n",
       "613884  -1.333511  40.187935  5812  \n",
       "613897  -3.150478  26.876560  6798  \n",
       "615245  42.544353  79.370140  2834  \n",
       "\n",
       "[579815 rows x 58 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#map sic to data\n",
    "data['sic'] = data['tic'].map(sic_map.set_index('tic')['sic'])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_features = ['net_working_capital', 'debt_ratio', 'debt_to_equity_ratio', 'm2b', 'working_capital_turnover']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in top_features:\n",
    "    new_col_name = col + '_industry_avg'\n",
    "    data[new_col_name] = data.groupby('sic')[col].transform('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CompNo</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>StkIndx</th>\n",
       "      <th>STInt</th>\n",
       "      <th>dtdlevel</th>\n",
       "      <th>dtdtrend</th>\n",
       "      <th>liqnonfinlevel</th>\n",
       "      <th>liqnonfintrend</th>\n",
       "      <th>ni2talevel</th>\n",
       "      <th>...</th>\n",
       "      <th>macd</th>\n",
       "      <th>macd_h</th>\n",
       "      <th>macd_s</th>\n",
       "      <th>rsi</th>\n",
       "      <th>sic</th>\n",
       "      <th>net_working_capital_industry_avg</th>\n",
       "      <th>debt_ratio_industry_avg</th>\n",
       "      <th>debt_to_equity_ratio_industry_avg</th>\n",
       "      <th>m2b_industry_avg</th>\n",
       "      <th>working_capital_turnover_industry_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26661</th>\n",
       "      <td>34285</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.097569</td>\n",
       "      <td>0.011896</td>\n",
       "      <td>-0.146043</td>\n",
       "      <td>0.019790</td>\n",
       "      <td>-0.143775</td>\n",
       "      <td>0.135087</td>\n",
       "      <td>0.002171</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.124699</td>\n",
       "      <td>-0.070089</td>\n",
       "      <td>-0.054610</td>\n",
       "      <td>39.313984</td>\n",
       "      <td>3490</td>\n",
       "      <td>364.879558</td>\n",
       "      <td>0.228628</td>\n",
       "      <td>0.536347</td>\n",
       "      <td>1.572063</td>\n",
       "      <td>0.891152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28323</th>\n",
       "      <td>27012</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.097569</td>\n",
       "      <td>0.011896</td>\n",
       "      <td>4.669174</td>\n",
       "      <td>1.296638</td>\n",
       "      <td>0.049928</td>\n",
       "      <td>-0.061520</td>\n",
       "      <td>0.006169</td>\n",
       "      <td>...</td>\n",
       "      <td>0.746325</td>\n",
       "      <td>0.434003</td>\n",
       "      <td>0.312323</td>\n",
       "      <td>73.233696</td>\n",
       "      <td>3480</td>\n",
       "      <td>255.967689</td>\n",
       "      <td>0.122428</td>\n",
       "      <td>0.435817</td>\n",
       "      <td>2.070154</td>\n",
       "      <td>1.000616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28324</th>\n",
       "      <td>41558</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.097569</td>\n",
       "      <td>0.011896</td>\n",
       "      <td>2.619373</td>\n",
       "      <td>0.604174</td>\n",
       "      <td>0.387817</td>\n",
       "      <td>0.336426</td>\n",
       "      <td>0.008513</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.917783</td>\n",
       "      <td>-0.331746</td>\n",
       "      <td>-0.586037</td>\n",
       "      <td>14.925373</td>\n",
       "      <td>2844</td>\n",
       "      <td>529.166736</td>\n",
       "      <td>0.229053</td>\n",
       "      <td>-2.692200</td>\n",
       "      <td>1.975378</td>\n",
       "      <td>-0.250182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28325</th>\n",
       "      <td>28960</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.097569</td>\n",
       "      <td>0.011896</td>\n",
       "      <td>0.169095</td>\n",
       "      <td>-0.026455</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000645</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025289</td>\n",
       "      <td>-0.036679</td>\n",
       "      <td>0.011390</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>6020</td>\n",
       "      <td>63.606360</td>\n",
       "      <td>0.146507</td>\n",
       "      <td>1.803026</td>\n",
       "      <td>0.786306</td>\n",
       "      <td>-0.012844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28326</th>\n",
       "      <td>28960</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.097569</td>\n",
       "      <td>0.011896</td>\n",
       "      <td>0.169095</td>\n",
       "      <td>-0.026455</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000645</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025289</td>\n",
       "      <td>-0.036679</td>\n",
       "      <td>0.011390</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>6020</td>\n",
       "      <td>63.606360</td>\n",
       "      <td>0.146507</td>\n",
       "      <td>1.803026</td>\n",
       "      <td>0.786306</td>\n",
       "      <td>-0.012844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613886</th>\n",
       "      <td>53941</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.120300</td>\n",
       "      <td>-0.010290</td>\n",
       "      <td>5.645101</td>\n",
       "      <td>0.280356</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003193</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.033162</td>\n",
       "      <td>-0.041029</td>\n",
       "      <td>0.007867</td>\n",
       "      <td>43.412176</td>\n",
       "      <td>6798</td>\n",
       "      <td>-32.488959</td>\n",
       "      <td>0.561950</td>\n",
       "      <td>2.013850</td>\n",
       "      <td>0.996649</td>\n",
       "      <td>-0.108899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613885</th>\n",
       "      <td>34205</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.011539</td>\n",
       "      <td>0.009881</td>\n",
       "      <td>4.451980</td>\n",
       "      <td>-0.293586</td>\n",
       "      <td>1.300011</td>\n",
       "      <td>0.586387</td>\n",
       "      <td>-0.017127</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.516866</td>\n",
       "      <td>-1.133378</td>\n",
       "      <td>-4.383488</td>\n",
       "      <td>46.610352</td>\n",
       "      <td>2836</td>\n",
       "      <td>473.122861</td>\n",
       "      <td>0.214359</td>\n",
       "      <td>2.558332</td>\n",
       "      <td>3.484895</td>\n",
       "      <td>0.180908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613884</th>\n",
       "      <td>34191</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.011539</td>\n",
       "      <td>0.009881</td>\n",
       "      <td>5.082761</td>\n",
       "      <td>-0.707860</td>\n",
       "      <td>-0.052495</td>\n",
       "      <td>-0.047746</td>\n",
       "      <td>0.007015</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.053199</td>\n",
       "      <td>-2.719688</td>\n",
       "      <td>-1.333511</td>\n",
       "      <td>40.187935</td>\n",
       "      <td>5812</td>\n",
       "      <td>25.512312</td>\n",
       "      <td>0.472314</td>\n",
       "      <td>-5.176918</td>\n",
       "      <td>1.960401</td>\n",
       "      <td>-3.477817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613897</th>\n",
       "      <td>53716</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.120300</td>\n",
       "      <td>-0.010290</td>\n",
       "      <td>4.231041</td>\n",
       "      <td>-0.429897</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001674</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.099552</td>\n",
       "      <td>-0.949074</td>\n",
       "      <td>-3.150478</td>\n",
       "      <td>26.876560</td>\n",
       "      <td>6798</td>\n",
       "      <td>-32.488959</td>\n",
       "      <td>0.561950</td>\n",
       "      <td>2.013850</td>\n",
       "      <td>0.996649</td>\n",
       "      <td>-0.108899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615245</th>\n",
       "      <td>27723</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.011539</td>\n",
       "      <td>0.009881</td>\n",
       "      <td>10.035608</td>\n",
       "      <td>1.044848</td>\n",
       "      <td>0.144421</td>\n",
       "      <td>0.117867</td>\n",
       "      <td>0.010069</td>\n",
       "      <td>...</td>\n",
       "      <td>46.540101</td>\n",
       "      <td>3.995748</td>\n",
       "      <td>42.544353</td>\n",
       "      <td>79.370140</td>\n",
       "      <td>2834</td>\n",
       "      <td>1285.497144</td>\n",
       "      <td>0.258816</td>\n",
       "      <td>0.534879</td>\n",
       "      <td>3.020036</td>\n",
       "      <td>-0.815998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>579815 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CompNo    year  month   StkIndx     STInt   dtdlevel  dtdtrend  \\\n",
       "26661    34285  2000.0     12 -0.097569  0.011896  -0.146043  0.019790   \n",
       "28323    27012  2000.0     12 -0.097569  0.011896   4.669174  1.296638   \n",
       "28324    41558  2000.0     12 -0.097569  0.011896   2.619373  0.604174   \n",
       "28325    28960  2000.0     12 -0.097569  0.011896   0.169095 -0.026455   \n",
       "28326    28960  2000.0     12 -0.097569  0.011896   0.169095 -0.026455   \n",
       "...        ...     ...    ...       ...       ...        ...       ...   \n",
       "613886   53941  2023.0      5 -0.120300 -0.010290   5.645101  0.280356   \n",
       "613885   34205  2023.0      5  0.011539  0.009881   4.451980 -0.293586   \n",
       "613884   34191  2023.0      5  0.011539  0.009881   5.082761 -0.707860   \n",
       "613897   53716  2023.0      5 -0.120300 -0.010290   4.231041 -0.429897   \n",
       "615245   27723  2023.0      5  0.011539  0.009881  10.035608  1.044848   \n",
       "\n",
       "        liqnonfinlevel  liqnonfintrend  ni2talevel  ...       macd    macd_h  \\\n",
       "26661        -0.143775        0.135087    0.002171  ...  -0.124699 -0.070089   \n",
       "28323         0.049928       -0.061520    0.006169  ...   0.746325  0.434003   \n",
       "28324         0.387817        0.336426    0.008513  ...  -0.917783 -0.331746   \n",
       "28325         0.000000        0.000000    0.000645  ...  -0.025289 -0.036679   \n",
       "28326         0.000000        0.000000    0.000645  ...  -0.025289 -0.036679   \n",
       "...                ...             ...         ...  ...        ...       ...   \n",
       "613886        0.000000        0.000000    0.003193  ...  -0.033162 -0.041029   \n",
       "613885        1.300011        0.586387   -0.017127  ...  -5.516866 -1.133378   \n",
       "613884       -0.052495       -0.047746    0.007015  ...  -4.053199 -2.719688   \n",
       "613897        0.000000        0.000000    0.001674  ...  -4.099552 -0.949074   \n",
       "615245        0.144421        0.117867    0.010069  ...  46.540101  3.995748   \n",
       "\n",
       "           macd_s        rsi   sic  net_working_capital_industry_avg  \\\n",
       "26661   -0.054610  39.313984  3490                        364.879558   \n",
       "28323    0.312323  73.233696  3480                        255.967689   \n",
       "28324   -0.586037  14.925373  2844                        529.166736   \n",
       "28325    0.011390  50.000000  6020                         63.606360   \n",
       "28326    0.011390  50.000000  6020                         63.606360   \n",
       "...           ...        ...   ...                               ...   \n",
       "613886   0.007867  43.412176  6798                        -32.488959   \n",
       "613885  -4.383488  46.610352  2836                        473.122861   \n",
       "613884  -1.333511  40.187935  5812                         25.512312   \n",
       "613897  -3.150478  26.876560  6798                        -32.488959   \n",
       "615245  42.544353  79.370140  2834                       1285.497144   \n",
       "\n",
       "        debt_ratio_industry_avg  debt_to_equity_ratio_industry_avg  \\\n",
       "26661                  0.228628                           0.536347   \n",
       "28323                  0.122428                           0.435817   \n",
       "28324                  0.229053                          -2.692200   \n",
       "28325                  0.146507                           1.803026   \n",
       "28326                  0.146507                           1.803026   \n",
       "...                         ...                                ...   \n",
       "613886                 0.561950                           2.013850   \n",
       "613885                 0.214359                           2.558332   \n",
       "613884                 0.472314                          -5.176918   \n",
       "613897                 0.561950                           2.013850   \n",
       "615245                 0.258816                           0.534879   \n",
       "\n",
       "        m2b_industry_avg  working_capital_turnover_industry_avg  \n",
       "26661           1.572063                               0.891152  \n",
       "28323           2.070154                               1.000616  \n",
       "28324           1.975378                              -0.250182  \n",
       "28325           0.786306                              -0.012844  \n",
       "28326           0.786306                              -0.012844  \n",
       "...                  ...                                    ...  \n",
       "613886          0.996649                              -0.108899  \n",
       "613885          3.484895                               0.180908  \n",
       "613884          1.960401                              -3.477817  \n",
       "613897          0.996649                              -0.108899  \n",
       "615245          3.020036                              -0.815998  \n",
       "\n",
       "[579815 rows x 63 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute relative ratio\n",
    "data['relative_net_working_capital'] = ((data['net_working_capital'] - data['net_working_capital_industry_avg']) / data['net_working_capital_industry_avg']) * 100\n",
    "data['relative_debt_ratio'] = ((data['debt_ratio'] - data['debt_ratio_industry_avg']) / data['debt_ratio_industry_avg']) * 100\n",
    "data['relative_debt_to_equity_ratio'] = ((data['debt_to_equity_ratio'] - data['debt_to_equity_ratio_industry_avg']) / data['debt_to_equity_ratio_industry_avg']) * 100\n",
    "data['relative_m2b'] = ((data['m2b'] - data['m2b_industry_avg']) / data['m2b_industry_avg']) * 100\n",
    "data['relative_working_capital_turnover'] = ((data['working_capital_turnover'] - data['working_capital_turnover_industry_avg']) / data['working_capital_turnover_industry_avg']) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CompNo</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>StkIndx</th>\n",
       "      <th>STInt</th>\n",
       "      <th>dtdlevel</th>\n",
       "      <th>dtdtrend</th>\n",
       "      <th>liqnonfinlevel</th>\n",
       "      <th>liqnonfintrend</th>\n",
       "      <th>ni2talevel</th>\n",
       "      <th>...</th>\n",
       "      <th>net_working_capital_industry_avg</th>\n",
       "      <th>debt_ratio_industry_avg</th>\n",
       "      <th>debt_to_equity_ratio_industry_avg</th>\n",
       "      <th>m2b_industry_avg</th>\n",
       "      <th>working_capital_turnover_industry_avg</th>\n",
       "      <th>relative_net_working_capital</th>\n",
       "      <th>relative_debt_ratio</th>\n",
       "      <th>relative_debt_to_equity_ratio</th>\n",
       "      <th>relative_m2b</th>\n",
       "      <th>relative_working_capital_turnover</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26661</th>\n",
       "      <td>34285</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.097569</td>\n",
       "      <td>0.011896</td>\n",
       "      <td>-0.146043</td>\n",
       "      <td>0.019790</td>\n",
       "      <td>-0.143775</td>\n",
       "      <td>0.135087</td>\n",
       "      <td>0.002171</td>\n",
       "      <td>...</td>\n",
       "      <td>364.879558</td>\n",
       "      <td>0.228628</td>\n",
       "      <td>0.536347</td>\n",
       "      <td>1.572063</td>\n",
       "      <td>0.891152</td>\n",
       "      <td>-100.414931</td>\n",
       "      <td>135.933343</td>\n",
       "      <td>506.229854</td>\n",
       "      <td>-42.319276</td>\n",
       "      <td>-4574.451369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28323</th>\n",
       "      <td>27012</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.097569</td>\n",
       "      <td>0.011896</td>\n",
       "      <td>4.669174</td>\n",
       "      <td>1.296638</td>\n",
       "      <td>0.049928</td>\n",
       "      <td>-0.061520</td>\n",
       "      <td>0.006169</td>\n",
       "      <td>...</td>\n",
       "      <td>255.967689</td>\n",
       "      <td>0.122428</td>\n",
       "      <td>0.435817</td>\n",
       "      <td>2.070154</td>\n",
       "      <td>1.000616</td>\n",
       "      <td>-96.430800</td>\n",
       "      <td>225.925957</td>\n",
       "      <td>365.423892</td>\n",
       "      <td>-17.998017</td>\n",
       "      <td>10524.304598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28324</th>\n",
       "      <td>41558</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.097569</td>\n",
       "      <td>0.011896</td>\n",
       "      <td>2.619373</td>\n",
       "      <td>0.604174</td>\n",
       "      <td>0.387817</td>\n",
       "      <td>0.336426</td>\n",
       "      <td>0.008513</td>\n",
       "      <td>...</td>\n",
       "      <td>529.166736</td>\n",
       "      <td>0.229053</td>\n",
       "      <td>-2.692200</td>\n",
       "      <td>1.975378</td>\n",
       "      <td>-0.250182</td>\n",
       "      <td>-76.787090</td>\n",
       "      <td>-37.274181</td>\n",
       "      <td>-108.597427</td>\n",
       "      <td>-46.309125</td>\n",
       "      <td>-833.679116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28325</th>\n",
       "      <td>28960</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.097569</td>\n",
       "      <td>0.011896</td>\n",
       "      <td>0.169095</td>\n",
       "      <td>-0.026455</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000645</td>\n",
       "      <td>...</td>\n",
       "      <td>63.606360</td>\n",
       "      <td>0.146507</td>\n",
       "      <td>1.803026</td>\n",
       "      <td>0.786306</td>\n",
       "      <td>-0.012844</td>\n",
       "      <td>-96.918547</td>\n",
       "      <td>117.897032</td>\n",
       "      <td>160.194707</td>\n",
       "      <td>11.716452</td>\n",
       "      <td>-100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28326</th>\n",
       "      <td>28960</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.097569</td>\n",
       "      <td>0.011896</td>\n",
       "      <td>0.169095</td>\n",
       "      <td>-0.026455</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000645</td>\n",
       "      <td>...</td>\n",
       "      <td>63.606360</td>\n",
       "      <td>0.146507</td>\n",
       "      <td>1.803026</td>\n",
       "      <td>0.786306</td>\n",
       "      <td>-0.012844</td>\n",
       "      <td>-96.918547</td>\n",
       "      <td>117.897032</td>\n",
       "      <td>160.194707</td>\n",
       "      <td>11.716452</td>\n",
       "      <td>-100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613886</th>\n",
       "      <td>53941</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.120300</td>\n",
       "      <td>-0.010290</td>\n",
       "      <td>5.645101</td>\n",
       "      <td>0.280356</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003193</td>\n",
       "      <td>...</td>\n",
       "      <td>-32.488959</td>\n",
       "      <td>0.561950</td>\n",
       "      <td>2.013850</td>\n",
       "      <td>0.996649</td>\n",
       "      <td>-0.108899</td>\n",
       "      <td>187.863952</td>\n",
       "      <td>-6.693288</td>\n",
       "      <td>-41.381743</td>\n",
       "      <td>-32.841745</td>\n",
       "      <td>129.773490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613885</th>\n",
       "      <td>34205</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.011539</td>\n",
       "      <td>0.009881</td>\n",
       "      <td>4.451980</td>\n",
       "      <td>-0.293586</td>\n",
       "      <td>1.300011</td>\n",
       "      <td>0.586387</td>\n",
       "      <td>-0.017127</td>\n",
       "      <td>...</td>\n",
       "      <td>473.122861</td>\n",
       "      <td>0.214359</td>\n",
       "      <td>2.558332</td>\n",
       "      <td>3.484895</td>\n",
       "      <td>0.180908</td>\n",
       "      <td>3.072381</td>\n",
       "      <td>-56.672709</td>\n",
       "      <td>-92.757512</td>\n",
       "      <td>1.153453</td>\n",
       "      <td>71.905611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613884</th>\n",
       "      <td>34191</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.011539</td>\n",
       "      <td>0.009881</td>\n",
       "      <td>5.082761</td>\n",
       "      <td>-0.707860</td>\n",
       "      <td>-0.052495</td>\n",
       "      <td>-0.047746</td>\n",
       "      <td>0.007015</td>\n",
       "      <td>...</td>\n",
       "      <td>25.512312</td>\n",
       "      <td>0.472314</td>\n",
       "      <td>-5.176918</td>\n",
       "      <td>1.960401</td>\n",
       "      <td>-3.477817</td>\n",
       "      <td>-202.037009</td>\n",
       "      <td>148.869455</td>\n",
       "      <td>-60.018508</td>\n",
       "      <td>63.814402</td>\n",
       "      <td>654.898866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613897</th>\n",
       "      <td>53716</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.120300</td>\n",
       "      <td>-0.010290</td>\n",
       "      <td>4.231041</td>\n",
       "      <td>-0.429897</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001674</td>\n",
       "      <td>...</td>\n",
       "      <td>-32.488959</td>\n",
       "      <td>0.561950</td>\n",
       "      <td>2.013850</td>\n",
       "      <td>0.996649</td>\n",
       "      <td>-0.108899</td>\n",
       "      <td>-3232.848963</td>\n",
       "      <td>-33.101713</td>\n",
       "      <td>-65.662333</td>\n",
       "      <td>-51.820454</td>\n",
       "      <td>-232.987136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615245</th>\n",
       "      <td>27723</td>\n",
       "      <td>2023.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.011539</td>\n",
       "      <td>0.009881</td>\n",
       "      <td>10.035608</td>\n",
       "      <td>1.044848</td>\n",
       "      <td>0.144421</td>\n",
       "      <td>0.117867</td>\n",
       "      <td>0.010069</td>\n",
       "      <td>...</td>\n",
       "      <td>1285.497144</td>\n",
       "      <td>0.258816</td>\n",
       "      <td>0.534879</td>\n",
       "      <td>3.020036</td>\n",
       "      <td>-0.815998</td>\n",
       "      <td>273.505303</td>\n",
       "      <td>37.240838</td>\n",
       "      <td>215.488609</td>\n",
       "      <td>114.324828</td>\n",
       "      <td>-399.399048</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>579815 rows × 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CompNo    year  month   StkIndx     STInt   dtdlevel  dtdtrend  \\\n",
       "26661    34285  2000.0     12 -0.097569  0.011896  -0.146043  0.019790   \n",
       "28323    27012  2000.0     12 -0.097569  0.011896   4.669174  1.296638   \n",
       "28324    41558  2000.0     12 -0.097569  0.011896   2.619373  0.604174   \n",
       "28325    28960  2000.0     12 -0.097569  0.011896   0.169095 -0.026455   \n",
       "28326    28960  2000.0     12 -0.097569  0.011896   0.169095 -0.026455   \n",
       "...        ...     ...    ...       ...       ...        ...       ...   \n",
       "613886   53941  2023.0      5 -0.120300 -0.010290   5.645101  0.280356   \n",
       "613885   34205  2023.0      5  0.011539  0.009881   4.451980 -0.293586   \n",
       "613884   34191  2023.0      5  0.011539  0.009881   5.082761 -0.707860   \n",
       "613897   53716  2023.0      5 -0.120300 -0.010290   4.231041 -0.429897   \n",
       "615245   27723  2023.0      5  0.011539  0.009881  10.035608  1.044848   \n",
       "\n",
       "        liqnonfinlevel  liqnonfintrend  ni2talevel  ...  \\\n",
       "26661        -0.143775        0.135087    0.002171  ...   \n",
       "28323         0.049928       -0.061520    0.006169  ...   \n",
       "28324         0.387817        0.336426    0.008513  ...   \n",
       "28325         0.000000        0.000000    0.000645  ...   \n",
       "28326         0.000000        0.000000    0.000645  ...   \n",
       "...                ...             ...         ...  ...   \n",
       "613886        0.000000        0.000000    0.003193  ...   \n",
       "613885        1.300011        0.586387   -0.017127  ...   \n",
       "613884       -0.052495       -0.047746    0.007015  ...   \n",
       "613897        0.000000        0.000000    0.001674  ...   \n",
       "615245        0.144421        0.117867    0.010069  ...   \n",
       "\n",
       "        net_working_capital_industry_avg  debt_ratio_industry_avg  \\\n",
       "26661                         364.879558                 0.228628   \n",
       "28323                         255.967689                 0.122428   \n",
       "28324                         529.166736                 0.229053   \n",
       "28325                          63.606360                 0.146507   \n",
       "28326                          63.606360                 0.146507   \n",
       "...                                  ...                      ...   \n",
       "613886                        -32.488959                 0.561950   \n",
       "613885                        473.122861                 0.214359   \n",
       "613884                         25.512312                 0.472314   \n",
       "613897                        -32.488959                 0.561950   \n",
       "615245                       1285.497144                 0.258816   \n",
       "\n",
       "        debt_to_equity_ratio_industry_avg  m2b_industry_avg  \\\n",
       "26661                            0.536347          1.572063   \n",
       "28323                            0.435817          2.070154   \n",
       "28324                           -2.692200          1.975378   \n",
       "28325                            1.803026          0.786306   \n",
       "28326                            1.803026          0.786306   \n",
       "...                                   ...               ...   \n",
       "613886                           2.013850          0.996649   \n",
       "613885                           2.558332          3.484895   \n",
       "613884                          -5.176918          1.960401   \n",
       "613897                           2.013850          0.996649   \n",
       "615245                           0.534879          3.020036   \n",
       "\n",
       "        working_capital_turnover_industry_avg  relative_net_working_capital  \\\n",
       "26661                                0.891152                   -100.414931   \n",
       "28323                                1.000616                    -96.430800   \n",
       "28324                               -0.250182                    -76.787090   \n",
       "28325                               -0.012844                    -96.918547   \n",
       "28326                               -0.012844                    -96.918547   \n",
       "...                                       ...                           ...   \n",
       "613886                              -0.108899                    187.863952   \n",
       "613885                               0.180908                      3.072381   \n",
       "613884                              -3.477817                   -202.037009   \n",
       "613897                              -0.108899                  -3232.848963   \n",
       "615245                              -0.815998                    273.505303   \n",
       "\n",
       "        relative_debt_ratio  relative_debt_to_equity_ratio  relative_m2b  \\\n",
       "26661            135.933343                     506.229854    -42.319276   \n",
       "28323            225.925957                     365.423892    -17.998017   \n",
       "28324            -37.274181                    -108.597427    -46.309125   \n",
       "28325            117.897032                     160.194707     11.716452   \n",
       "28326            117.897032                     160.194707     11.716452   \n",
       "...                     ...                            ...           ...   \n",
       "613886            -6.693288                     -41.381743    -32.841745   \n",
       "613885           -56.672709                     -92.757512      1.153453   \n",
       "613884           148.869455                     -60.018508     63.814402   \n",
       "613897           -33.101713                     -65.662333    -51.820454   \n",
       "615245            37.240838                     215.488609    114.324828   \n",
       "\n",
       "        relative_working_capital_turnover  \n",
       "26661                        -4574.451369  \n",
       "28323                        10524.304598  \n",
       "28324                         -833.679116  \n",
       "28325                         -100.000000  \n",
       "28326                         -100.000000  \n",
       "...                                   ...  \n",
       "613886                         129.773490  \n",
       "613885                          71.905611  \n",
       "613884                         654.898866  \n",
       "613897                        -232.987136  \n",
       "615245                        -399.399048  \n",
       "\n",
       "[579815 rows x 68 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "relative_debt_to_equity_ratio        109\n",
       "relative_debt_ratio                  109\n",
       "CompNo                                 0\n",
       "day_sales_outstanding                  0\n",
       "operating_profit_margin                0\n",
       "                                    ... \n",
       "current_ratio                          0\n",
       "quick_ratio                            0\n",
       "cash_ratio                             0\n",
       "net_working_capital                    0\n",
       "relative_working_capital_turnover      0\n",
       "Length: 68, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum().sort_values(ascending= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CompNo</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>StkIndx</th>\n",
       "      <th>STInt</th>\n",
       "      <th>dtdlevel</th>\n",
       "      <th>dtdtrend</th>\n",
       "      <th>liqnonfinlevel</th>\n",
       "      <th>liqnonfintrend</th>\n",
       "      <th>ni2talevel</th>\n",
       "      <th>...</th>\n",
       "      <th>net_working_capital_industry_avg</th>\n",
       "      <th>debt_ratio_industry_avg</th>\n",
       "      <th>debt_to_equity_ratio_industry_avg</th>\n",
       "      <th>m2b_industry_avg</th>\n",
       "      <th>working_capital_turnover_industry_avg</th>\n",
       "      <th>relative_net_working_capital</th>\n",
       "      <th>relative_debt_ratio</th>\n",
       "      <th>relative_debt_to_equity_ratio</th>\n",
       "      <th>relative_m2b</th>\n",
       "      <th>relative_working_capital_turnover</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27700</th>\n",
       "      <td>36979</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.097569</td>\n",
       "      <td>0.011896</td>\n",
       "      <td>6.197062</td>\n",
       "      <td>0.547306</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010622</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.248894</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.347761</td>\n",
       "      <td>-23.358312</td>\n",
       "      <td>-91.160913</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-44.409540</td>\n",
       "      <td>154.727306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30091</th>\n",
       "      <td>36979</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.020346</td>\n",
       "      <td>0.008312</td>\n",
       "      <td>6.214000</td>\n",
       "      <td>1.037391</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010474</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.248894</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.347761</td>\n",
       "      <td>-23.358312</td>\n",
       "      <td>-72.277410</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-46.656232</td>\n",
       "      <td>104.462700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36489</th>\n",
       "      <td>36979</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.115993</td>\n",
       "      <td>0.002831</td>\n",
       "      <td>8.129290</td>\n",
       "      <td>5.048892</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000807</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.248894</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.347761</td>\n",
       "      <td>-23.358312</td>\n",
       "      <td>-6.988702</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-37.348265</td>\n",
       "      <td>85.158924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38628</th>\n",
       "      <td>36979</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.151117</td>\n",
       "      <td>0.002990</td>\n",
       "      <td>8.852637</td>\n",
       "      <td>5.116028</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000746</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.248894</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.347761</td>\n",
       "      <td>-23.358312</td>\n",
       "      <td>-88.348477</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-37.208685</td>\n",
       "      <td>-27.923642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38933</th>\n",
       "      <td>36979</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.153477</td>\n",
       "      <td>0.002465</td>\n",
       "      <td>9.504988</td>\n",
       "      <td>4.597169</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000633</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.248894</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.347761</td>\n",
       "      <td>-23.358312</td>\n",
       "      <td>-88.348477</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-37.334069</td>\n",
       "      <td>-27.923642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130586</th>\n",
       "      <td>36979</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>12</td>\n",
       "      <td>0.028627</td>\n",
       "      <td>0.004653</td>\n",
       "      <td>7.725425</td>\n",
       "      <td>0.010150</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005567</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.248894</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.347761</td>\n",
       "      <td>-23.358312</td>\n",
       "      <td>-34.108627</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.885908</td>\n",
       "      <td>9.243596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130584</th>\n",
       "      <td>36979</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>12</td>\n",
       "      <td>0.028627</td>\n",
       "      <td>0.004653</td>\n",
       "      <td>7.725425</td>\n",
       "      <td>0.010150</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005567</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.248894</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.347761</td>\n",
       "      <td>-23.358312</td>\n",
       "      <td>-34.108627</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.885908</td>\n",
       "      <td>9.243596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130583</th>\n",
       "      <td>36979</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>12</td>\n",
       "      <td>0.028627</td>\n",
       "      <td>0.004653</td>\n",
       "      <td>7.725425</td>\n",
       "      <td>0.010150</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005567</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.248894</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.347761</td>\n",
       "      <td>-23.358312</td>\n",
       "      <td>-34.108627</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.885908</td>\n",
       "      <td>9.243596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130582</th>\n",
       "      <td>36979</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>12</td>\n",
       "      <td>0.028627</td>\n",
       "      <td>0.004653</td>\n",
       "      <td>7.725425</td>\n",
       "      <td>0.010150</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005567</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.248894</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.347761</td>\n",
       "      <td>-23.358312</td>\n",
       "      <td>-34.108627</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.885908</td>\n",
       "      <td>9.243596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130585</th>\n",
       "      <td>36979</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>12</td>\n",
       "      <td>0.028627</td>\n",
       "      <td>0.004653</td>\n",
       "      <td>7.725425</td>\n",
       "      <td>0.010150</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005567</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.248894</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.347761</td>\n",
       "      <td>-23.358312</td>\n",
       "      <td>-34.108627</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>29.885908</td>\n",
       "      <td>9.243596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>109 rows × 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CompNo    year  month   StkIndx     STInt  dtdlevel  dtdtrend  \\\n",
       "27700    36979  2000.0     12 -0.097569  0.011896  6.197062  0.547306   \n",
       "30091    36979  2001.0      1 -0.020346  0.008312  6.214000  1.037391   \n",
       "36489    36979  2001.0      5 -0.115993  0.002831  8.129290  5.048892   \n",
       "38628    36979  2001.0      6 -0.151117  0.002990  8.852637  5.116028   \n",
       "38933    36979  2001.0      7 -0.153477  0.002465  9.504988  4.597169   \n",
       "...        ...     ...    ...       ...       ...       ...       ...   \n",
       "130586   36979  2005.0     12  0.028627  0.004653  7.725425  0.010150   \n",
       "130584   36979  2005.0     12  0.028627  0.004653  7.725425  0.010150   \n",
       "130583   36979  2005.0     12  0.028627  0.004653  7.725425  0.010150   \n",
       "130582   36979  2005.0     12  0.028627  0.004653  7.725425  0.010150   \n",
       "130585   36979  2005.0     12  0.028627  0.004653  7.725425  0.010150   \n",
       "\n",
       "        liqnonfinlevel  liqnonfintrend  ni2talevel  ...  \\\n",
       "27700              0.0             0.0    0.010622  ...   \n",
       "30091              0.0             0.0    0.010474  ...   \n",
       "36489              0.0             0.0    0.000807  ...   \n",
       "38628              0.0             0.0    0.000746  ...   \n",
       "38933              0.0             0.0    0.000633  ...   \n",
       "...                ...             ...         ...  ...   \n",
       "130586             0.0             0.0    0.005567  ...   \n",
       "130584             0.0             0.0    0.005567  ...   \n",
       "130583             0.0             0.0    0.005567  ...   \n",
       "130582             0.0             0.0    0.005567  ...   \n",
       "130585             0.0             0.0    0.005567  ...   \n",
       "\n",
       "        net_working_capital_industry_avg  debt_ratio_industry_avg  \\\n",
       "27700                          -0.248894                      0.0   \n",
       "30091                          -0.248894                      0.0   \n",
       "36489                          -0.248894                      0.0   \n",
       "38628                          -0.248894                      0.0   \n",
       "38933                          -0.248894                      0.0   \n",
       "...                                  ...                      ...   \n",
       "130586                         -0.248894                      0.0   \n",
       "130584                         -0.248894                      0.0   \n",
       "130583                         -0.248894                      0.0   \n",
       "130582                         -0.248894                      0.0   \n",
       "130585                         -0.248894                      0.0   \n",
       "\n",
       "        debt_to_equity_ratio_industry_avg  m2b_industry_avg  \\\n",
       "27700                                 0.0          2.347761   \n",
       "30091                                 0.0          2.347761   \n",
       "36489                                 0.0          2.347761   \n",
       "38628                                 0.0          2.347761   \n",
       "38933                                 0.0          2.347761   \n",
       "...                                   ...               ...   \n",
       "130586                                0.0          2.347761   \n",
       "130584                                0.0          2.347761   \n",
       "130583                                0.0          2.347761   \n",
       "130582                                0.0          2.347761   \n",
       "130585                                0.0          2.347761   \n",
       "\n",
       "        working_capital_turnover_industry_avg  relative_net_working_capital  \\\n",
       "27700                              -23.358312                    -91.160913   \n",
       "30091                              -23.358312                    -72.277410   \n",
       "36489                              -23.358312                     -6.988702   \n",
       "38628                              -23.358312                    -88.348477   \n",
       "38933                              -23.358312                    -88.348477   \n",
       "...                                       ...                           ...   \n",
       "130586                             -23.358312                    -34.108627   \n",
       "130584                             -23.358312                    -34.108627   \n",
       "130583                             -23.358312                    -34.108627   \n",
       "130582                             -23.358312                    -34.108627   \n",
       "130585                             -23.358312                    -34.108627   \n",
       "\n",
       "        relative_debt_ratio  relative_debt_to_equity_ratio  relative_m2b  \\\n",
       "27700                   NaN                            NaN    -44.409540   \n",
       "30091                   NaN                            NaN    -46.656232   \n",
       "36489                   NaN                            NaN    -37.348265   \n",
       "38628                   NaN                            NaN    -37.208685   \n",
       "38933                   NaN                            NaN    -37.334069   \n",
       "...                     ...                            ...           ...   \n",
       "130586                  NaN                            NaN     29.885908   \n",
       "130584                  NaN                            NaN     29.885908   \n",
       "130583                  NaN                            NaN     29.885908   \n",
       "130582                  NaN                            NaN     29.885908   \n",
       "130585                  NaN                            NaN     29.885908   \n",
       "\n",
       "        relative_working_capital_turnover  \n",
       "27700                          154.727306  \n",
       "30091                          104.462700  \n",
       "36489                           85.158924  \n",
       "38628                          -27.923642  \n",
       "38933                          -27.923642  \n",
       "...                                   ...  \n",
       "130586                           9.243596  \n",
       "130584                           9.243596  \n",
       "130583                           9.243596  \n",
       "130582                           9.243596  \n",
       "130585                           9.243596  \n",
       "\n",
       "[109 rows x 68 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data.isna().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in top_features:\n",
    "    new_col_name = col + '_industry_avg'\n",
    "    data.drop(columns = [new_col_name], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sort_values(by='EventDate', inplace=True)\n",
    "date2022 = datetime.datetime(2022, 1, 1)\n",
    "date2020 = datetime.datetime(2020,1,1)\n",
    "train_df = data[data[\"EventDate\"] < date2020]\n",
    "validation_df = data[(data[\"EventDate\"] >= date2020) & (data[\"EventDate\"] < date2022)]\n",
    "test_df = data[data[\"EventDate\"] >= date2022]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shiho\\AppData\\Local\\Temp\\ipykernel_20356\\215636084.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train_df.drop([\"CompNo\", \"year\", \"month\", \"day\", \"date\",'tic','sic','Duration','EventDate','StartDate','gvkey'], axis=1, inplace=True)\n",
      "C:\\Users\\shiho\\AppData\\Local\\Temp\\ipykernel_20356\\215636084.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  validation_df.drop([\"CompNo\", \"year\", \"month\", \"day\", \"date\",'tic','sic','Duration','EventDate','StartDate','gvkey'], axis=1, inplace=True)\n",
      "C:\\Users\\shiho\\AppData\\Local\\Temp\\ipykernel_20356\\215636084.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  test_df.drop([\"CompNo\", \"year\", \"month\", \"day\", \"date\",'tic','sic','Duration','EventDate','StartDate','gvkey'], axis=1, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "train_df.drop([\"CompNo\", \"year\", \"month\", \"day\", \"date\",'tic','sic','Duration','EventDate','StartDate','gvkey'], axis=1, inplace=True)\n",
    "validation_df.drop([\"CompNo\", \"year\", \"month\", \"day\", \"date\",'tic','sic','Duration','EventDate','StartDate','gvkey'], axis=1, inplace=True)\n",
    "test_df.drop([\"CompNo\", \"year\", \"month\", \"day\", \"date\",'tic','sic','Duration','EventDate','StartDate','gvkey'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_df.drop('Default', axis=1)\n",
    "y_train = train_df['Default']\n",
    "x_validation = validation_df.drop('Default', axis=1)\n",
    "y_validation = validation_df['Default']\n",
    "x_test= test_df.drop('Default', axis=1)\n",
    "y_test = test_df[\"Default\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['StkIndx', 'STInt', 'dtdlevel', 'dtdtrend', 'liqnonfinlevel',\n",
       "       'liqnonfintrend', 'ni2talevel', 'ni2tatrend', 'sizelevel', 'sizetrend',\n",
       "       'm2b', 'sigma', 'liqfinlevel', 'lqfintrend', 'DTDmedianFin',\n",
       "       'DTDmedianNonFin', 'dummy297fin', 'current_ratio', 'quick_ratio',\n",
       "       'cash_ratio', 'net_working_capital', 'debt_ratio',\n",
       "       'debt_to_equity_ratio', 'equity_ratio', 'cashflow_to_debt_ratio',\n",
       "       'net_profit_margin', 'return_on_assets', 'asset_turnover',\n",
       "       'inventory_turnover', 'days_in_inventory', 'receivables_turnover',\n",
       "       'day_sales_outstanding', 'working_capital_turnover',\n",
       "       'price_to_earnings', 'dividend_payout_ratio', 'retention_ratio',\n",
       "       'gross_margin_ratio', 'operating_profit_margin', 'ebitda_margin',\n",
       "       'debt_service_coverage_ratio', 'interest_coverage_ratio',\n",
       "       'Rolling_Sortino', 'macd', 'macd_h', 'macd_s', 'rsi',\n",
       "       'relative_net_working_capital', 'relative_debt_ratio',\n",
       "       'relative_debt_to_equity_ratio', 'relative_m2b',\n",
       "       'relative_working_capital_turnover'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-07 01:11:38,465] A new study created in memory with name: no-name-b9115bb6-2fac-4420-9e54-033e7d285ed3\n",
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1073, number of negative: 492317\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.093260 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12732\n",
      "[LightGBM] [Info] Number of data points in the train set: 493390, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002175 -> initscore=-6.128664\n",
      "[LightGBM] [Info] Start training from score -6.128664\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-07 01:11:45,805] Trial 0 finished with value: 0.7204615647615249 and parameters: {'num_leaves': 228, 'lambda_l1': 0.0015959145641941638, 'lambda_l2': 1.2360084397477081e-08, 'feature_fraction': 0.9850006812836715, 'min_child_samples': 40, 'learning_rate': 0.509598302627465, 'max_depth': 32, 'num_boost_round': 389}. Best is trial 0 with value: 0.7204615647615249.\n",
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1073, number of negative: 492317\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.086532 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12732\n",
      "[LightGBM] [Info] Number of data points in the train set: 493390, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002175 -> initscore=-6.128664\n",
      "[LightGBM] [Info] Start training from score -6.128664\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-07 01:11:50,640] Trial 1 finished with value: 0.6919758010902806 and parameters: {'num_leaves': 187, 'lambda_l1': 1.3591903400791379, 'lambda_l2': 0.23327764818874744, 'feature_fraction': 0.6195912549824408, 'min_child_samples': 55, 'learning_rate': 0.4518399702643596, 'max_depth': 211, 'num_boost_round': 186}. Best is trial 0 with value: 0.7204615647615249.\n",
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1073, number of negative: 492317\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.088595 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12732\n",
      "[LightGBM] [Info] Number of data points in the train set: 493390, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002175 -> initscore=-6.128664\n",
      "[LightGBM] [Info] Start training from score -6.128664\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-07 01:11:53,773] Trial 2 finished with value: 0.7089885463559178 and parameters: {'num_leaves': 32, 'lambda_l1': 2.8365809995126433e-06, 'lambda_l2': 0.00046008105265384855, 'feature_fraction': 0.7538924812616286, 'min_child_samples': 22, 'learning_rate': 1.3781997318010035, 'max_depth': 143, 'num_boost_round': 137}. Best is trial 0 with value: 0.7204615647615249.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1073, number of negative: 492317\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.091199 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12732\n",
      "[LightGBM] [Info] Number of data points in the train set: 493390, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002175 -> initscore=-6.128664\n",
      "[LightGBM] [Info] Start training from score -6.128664\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-07 01:11:58,231] Trial 3 finished with value: 0.7381839421049634 and parameters: {'num_leaves': 233, 'lambda_l1': 0.000726013112483077, 'lambda_l2': 3.0057638275969694e-08, 'feature_fraction': 0.5618799948731354, 'min_child_samples': 96, 'learning_rate': 0.45357005617116825, 'max_depth': 66, 'num_boost_round': 233}. Best is trial 3 with value: 0.7381839421049634.\n",
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1073, number of negative: 492317\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.081126 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12732\n",
      "[LightGBM] [Info] Number of data points in the train set: 493390, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002175 -> initscore=-6.128664\n",
      "[LightGBM] [Info] Start training from score -6.128664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-07 01:12:16,125] Trial 4 finished with value: 0.90910276622283 and parameters: {'num_leaves': 159, 'lambda_l1': 2.3256628627338907e-06, 'lambda_l2': 0.0001280905424494112, 'feature_fraction': 0.459961596371304, 'min_child_samples': 11, 'learning_rate': 0.00504105123900401, 'max_depth': 235, 'num_boost_round': 418}. Best is trial 4 with value: 0.90910276622283.\n",
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1073, number of negative: 492317\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.135945 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12732\n",
      "[LightGBM] [Info] Number of data points in the train set: 493390, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002175 -> initscore=-6.128664\n",
      "[LightGBM] [Info] Start training from score -6.128664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[I 2023-11-07 01:12:28,400] Trial 5 finished with value: 0.9161609715020165 and parameters: {'num_leaves': 202, 'lambda_l1': 0.04409160164548039, 'lambda_l2': 8.34545595494867e-08, 'feature_fraction': 0.5263040840889474, 'min_child_samples': 37, 'learning_rate': 6.570051155915669e-05, 'max_depth': 73, 'num_boost_round': 227}. Best is trial 5 with value: 0.9161609715020165.\n",
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1073, number of negative: 492317\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.101623 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12732\n",
      "[LightGBM] [Info] Number of data points in the train set: 493390, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002175 -> initscore=-6.128664\n",
      "[LightGBM] [Info] Start training from score -6.128664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-07 01:12:35,618] Trial 6 finished with value: 0.6551716780316701 and parameters: {'num_leaves': 4, 'lambda_l1': 8.70284856559397e-08, 'lambda_l2': 0.6552907985535694, 'feature_fraction': 0.9162963518331642, 'min_child_samples': 62, 'learning_rate': 0.14136789657704302, 'max_depth': 24, 'num_boost_round': 394}. Best is trial 5 with value: 0.9161609715020165.\n",
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1073, number of negative: 492317\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.093113 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12732\n",
      "[LightGBM] [Info] Number of data points in the train set: 493390, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002175 -> initscore=-6.128664\n",
      "[LightGBM] [Info] Start training from score -6.128664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[I 2023-11-07 01:12:55,874] Trial 7 finished with value: 0.8840222614773873 and parameters: {'num_leaves': 137, 'lambda_l1': 4.993069568803941e-06, 'lambda_l2': 2.5224081978379395e-05, 'feature_fraction': 0.8683851113493595, 'min_child_samples': 46, 'learning_rate': 0.0010715434218706845, 'max_depth': 247, 'num_boost_round': 357}. Best is trial 5 with value: 0.9161609715020165.\n",
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1073, number of negative: 492317\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.096621 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12732\n",
      "[LightGBM] [Info] Number of data points in the train set: 493390, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002175 -> initscore=-6.128664\n",
      "[LightGBM] [Info] Start training from score -6.128664\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[I 2023-11-07 01:13:04,293] Trial 8 finished with value: 0.9228267517617338 and parameters: {'num_leaves': 182, 'lambda_l1': 1.2666569965765428, 'lambda_l2': 0.24998941171449063, 'feature_fraction': 0.41349102722297143, 'min_child_samples': 42, 'learning_rate': 2.1983825444546956e-05, 'max_depth': 219, 'num_boost_round': 240}. Best is trial 8 with value: 0.9228267517617338.\n",
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1073, number of negative: 492317\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.094512 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12732\n",
      "[LightGBM] [Info] Number of data points in the train set: 493390, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002175 -> initscore=-6.128664\n",
      "[LightGBM] [Info] Start training from score -6.128664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-11-07 01:13:20,034] Trial 9 finished with value: 0.9174898221487771 and parameters: {'num_leaves': 47, 'lambda_l1': 0.004065507282354645, 'lambda_l2': 1.964862893984073e-06, 'feature_fraction': 0.8872283967805141, 'min_child_samples': 17, 'learning_rate': 0.00826519374085756, 'max_depth': 82, 'num_boost_round': 373}. Best is trial 8 with value: 0.9228267517617338.\n",
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1073, number of negative: 492317\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.130264 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12732\n",
      "[LightGBM] [Info] Number of data points in the train set: 493390, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002175 -> initscore=-6.128664\n",
      "[LightGBM] [Info] Start training from score -6.128664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[I 2023-11-07 01:13:29,931] Trial 10 finished with value: 0.9058568706035798 and parameters: {'num_leaves': 93, 'lambda_l1': 8.227918493475807, 'lambda_l2': 4.279750598703497, 'feature_fraction': 0.40044093328863223, 'min_child_samples': 80, 'learning_rate': 7.230923409620265e-07, 'max_depth': 175, 'num_boost_round': 299}. Best is trial 8 with value: 0.9228267517617338.\n",
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1073, number of negative: 492317\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.085665 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12732\n",
      "[LightGBM] [Info] Number of data points in the train set: 493390, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002175 -> initscore=-6.128664\n",
      "[LightGBM] [Info] Start training from score -6.128664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[I 2023-11-07 01:13:53,133] Trial 11 finished with value: 0.9021647324000734 and parameters: {'num_leaves': 79, 'lambda_l1': 0.07976906301386144, 'lambda_l2': 0.030630534666336296, 'feature_fraction': 0.7385351993927627, 'min_child_samples': 7, 'learning_rate': 1.4073284438235335e-05, 'max_depth': 111, 'num_boost_round': 488}. Best is trial 8 with value: 0.9228267517617338.\n",
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1073, number of negative: 492317\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.107768 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12732\n",
      "[LightGBM] [Info] Number of data points in the train set: 493390, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002175 -> initscore=-6.128664\n",
      "[LightGBM] [Info] Start training from score -6.128664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[I 2023-11-07 01:14:07,521] Trial 12 finished with value: 0.9210311445413161 and parameters: {'num_leaves': 87, 'lambda_l1': 0.04986649259808059, 'lambda_l2': 2.668133536308894e-06, 'feature_fraction': 0.665549022039373, 'min_child_samples': 26, 'learning_rate': 2.8396964063117872e-08, 'max_depth': 118, 'num_boost_round': 297}. Best is trial 8 with value: 0.9228267517617338.\n",
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1073, number of negative: 492317\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.088802 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12732\n",
      "[LightGBM] [Info] Number of data points in the train set: 493390, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002175 -> initscore=-6.128664\n",
      "[LightGBM] [Info] Start training from score -6.128664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[I 2023-11-07 01:14:19,744] Trial 13 finished with value: 0.9188962967183948 and parameters: {'num_leaves': 104, 'lambda_l1': 0.285922779983748, 'lambda_l2': 0.007641127721319029, 'feature_fraction': 0.6420904460808768, 'min_child_samples': 29, 'learning_rate': 8.554586691471029e-08, 'max_depth': 170, 'num_boost_round': 294}. Best is trial 8 with value: 0.9228267517617338.\n",
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1073, number of negative: 492317\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.079662 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12732\n",
      "[LightGBM] [Info] Number of data points in the train set: 493390, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002175 -> initscore=-6.128664\n",
      "[LightGBM] [Info] Start training from score -6.128664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[I 2023-11-07 01:14:24,223] Trial 14 finished with value: 0.9282044560943643 and parameters: {'num_leaves': 155, 'lambda_l1': 0.02714429713674386, 'lambda_l2': 0.0036153423463544335, 'feature_fraction': 0.4969707576122183, 'min_child_samples': 68, 'learning_rate': 1.2765999910585649e-08, 'max_depth': 122, 'num_boost_round': 104}. Best is trial 14 with value: 0.9282044560943643.\n",
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1073, number of negative: 492317\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.064026 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12732\n",
      "[LightGBM] [Info] Number of data points in the train set: 493390, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002175 -> initscore=-6.128664\n",
      "[LightGBM] [Info] Start training from score -6.128664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[I 2023-11-07 01:14:28,786] Trial 15 finished with value: 0.9310846455321924 and parameters: {'num_leaves': 159, 'lambda_l1': 4.9850366822912, 'lambda_l2': 0.004710343517864516, 'feature_fraction': 0.4036672769004093, 'min_child_samples': 69, 'learning_rate': 1.4302240901762408e-08, 'max_depth': 187, 'num_boost_round': 110}. Best is trial 15 with value: 0.9310846455321924.\n",
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1073, number of negative: 492317\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.074236 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12732\n",
      "[LightGBM] [Info] Number of data points in the train set: 493390, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002175 -> initscore=-6.128664\n",
      "[LightGBM] [Info] Start training from score -6.128664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[I 2023-11-07 01:14:32,970] Trial 16 finished with value: 0.9247539270993599 and parameters: {'num_leaves': 139, 'lambda_l1': 6.249652568098542, 'lambda_l2': 0.007501612943498571, 'feature_fraction': 0.48573681153355736, 'min_child_samples': 70, 'learning_rate': 3.913532187090386e-07, 'max_depth': 180, 'num_boost_round': 100}. Best is trial 15 with value: 0.9310846455321924.\n",
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1073, number of negative: 492317\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.064754 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12732\n",
      "[LightGBM] [Info] Number of data points in the train set: 493390, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002175 -> initscore=-6.128664\n",
      "[LightGBM] [Info] Start training from score -6.128664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[I 2023-11-07 01:14:41,335] Trial 17 finished with value: 0.9258725726695411 and parameters: {'num_leaves': 164, 'lambda_l1': 0.004746093823381564, 'lambda_l2': 0.0015217630922096535, 'feature_fraction': 0.5252903962843659, 'min_child_samples': 83, 'learning_rate': 1.0754030250703379e-08, 'max_depth': 144, 'num_boost_round': 157}. Best is trial 15 with value: 0.9310846455321924.\n",
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1073, number of negative: 492317\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.085893 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12732\n",
      "[LightGBM] [Info] Number of data points in the train set: 493390, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002175 -> initscore=-6.128664\n",
      "[LightGBM] [Info] Start training from score -6.128664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[I 2023-11-07 01:14:46,702] Trial 18 finished with value: 0.9388526095187443 and parameters: {'num_leaves': 253, 'lambda_l1': 0.26576247754578763, 'lambda_l2': 0.0012145364928208499, 'feature_fraction': 0.44558846681688774, 'min_child_samples': 71, 'learning_rate': 1.0108400272043569e-08, 'max_depth': 197, 'num_boost_round': 100}. Best is trial 18 with value: 0.9388526095187443.\n",
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1073, number of negative: 492317\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.068731 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12732\n",
      "[LightGBM] [Info] Number of data points in the train set: 493390, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002175 -> initscore=-6.128664\n",
      "[LightGBM] [Info] Start training from score -6.128664\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[I 2023-11-07 01:14:55,137] Trial 19 finished with value: 0.936283295661038 and parameters: {'num_leaves': 253, 'lambda_l1': 1.349667034423638, 'lambda_l2': 0.02938804899466178, 'feature_fraction': 0.43563120721939297, 'min_child_samples': 94, 'learning_rate': 1.1376566997201884e-06, 'max_depth': 200, 'num_boost_round': 179}. Best is trial 18 with value: 0.9388526095187443.\n",
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1073, number of negative: 492317\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.087245 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12732\n",
      "[LightGBM] [Info] Number of data points in the train set: 493390, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002175 -> initscore=-6.128664\n",
      "[LightGBM] [Info] Start training from score -6.128664\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[I 2023-11-07 01:15:05,167] Trial 20 finished with value: 0.9249904711252936 and parameters: {'num_leaves': 255, 'lambda_l1': 0.0001672253318188555, 'lambda_l2': 0.06372206589094251, 'feature_fraction': 0.5698840400728994, 'min_child_samples': 97, 'learning_rate': 2.216647765825113e-06, 'max_depth': 218, 'num_boost_round': 185}. Best is trial 18 with value: 0.9388526095187443.\n",
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1073, number of negative: 492317\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.077244 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12732\n",
      "[LightGBM] [Info] Number of data points in the train set: 493390, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002175 -> initscore=-6.128664\n",
      "[LightGBM] [Info] Start training from score -6.128664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[I 2023-11-07 01:15:12,346] Trial 21 finished with value: 0.9354897081821693 and parameters: {'num_leaves': 215, 'lambda_l1': 0.7865493938472319, 'lambda_l2': 0.0006724938863352948, 'feature_fraction': 0.45304495110489834, 'min_child_samples': 83, 'learning_rate': 1.3761872901033635e-07, 'max_depth': 195, 'num_boost_round': 142}. Best is trial 18 with value: 0.9388526095187443.\n",
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1073, number of negative: 492317\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.082896 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12732\n",
      "[LightGBM] [Info] Number of data points in the train set: 493390, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002175 -> initscore=-6.128664\n",
      "[LightGBM] [Info] Start training from score -6.128664\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[I 2023-11-07 01:15:19,194] Trial 22 finished with value: 0.9357618351156445 and parameters: {'num_leaves': 249, 'lambda_l1': 0.4309265192818985, 'lambda_l2': 0.0003892967728150534, 'feature_fraction': 0.43886120400512574, 'min_child_samples': 86, 'learning_rate': 1.8080474888089714e-07, 'max_depth': 199, 'num_boost_round': 161}. Best is trial 18 with value: 0.9388526095187443.\n",
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1073, number of negative: 492317\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.073351 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12732\n",
      "[LightGBM] [Info] Number of data points in the train set: 493390, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002175 -> initscore=-6.128664\n",
      "[LightGBM] [Info] Start training from score -6.128664\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[I 2023-11-07 01:15:27,048] Trial 23 finished with value: 0.9335698773592671 and parameters: {'num_leaves': 252, 'lambda_l1': 0.2977391001978723, 'lambda_l2': 6.614395831322189e-05, 'feature_fraction': 0.45685659852148075, 'min_child_samples': 92, 'learning_rate': 2.2358166940914063e-06, 'max_depth': 253, 'num_boost_round': 189}. Best is trial 18 with value: 0.9388526095187443.\n",
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1073, number of negative: 492317\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.086633 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12732\n",
      "[LightGBM] [Info] Number of data points in the train set: 493390, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002175 -> initscore=-6.128664\n",
      "[LightGBM] [Info] Start training from score -6.128664\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[I 2023-11-07 01:15:35,541] Trial 24 finished with value: 0.9254730563944764 and parameters: {'num_leaves': 235, 'lambda_l1': 0.28682132483211, 'lambda_l2': 0.00044255774288222795, 'feature_fraction': 0.5806811663632598, 'min_child_samples': 87, 'learning_rate': 9.371386975810847e-08, 'max_depth': 162, 'num_boost_round': 163}. Best is trial 18 with value: 0.9388526095187443.\n",
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1073, number of negative: 492317\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.075505 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12732\n",
      "[LightGBM] [Info] Number of data points in the train set: 493390, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002175 -> initscore=-6.128664\n",
      "[LightGBM] [Info] Start training from score -6.128664\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[I 2023-11-07 01:15:46,658] Trial 25 finished with value: 0.9263916272532147 and parameters: {'num_leaves': 206, 'lambda_l1': 0.01263171066660222, 'lambda_l2': 0.028359799203155445, 'feature_fraction': 0.5023399305592752, 'min_child_samples': 77, 'learning_rate': 6.972659089572905e-07, 'max_depth': 204, 'num_boost_round': 262}. Best is trial 18 with value: 0.9388526095187443.\n",
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1073, number of negative: 492317\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.097503 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12732\n",
      "[LightGBM] [Info] Number of data points in the train set: 493390, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002175 -> initscore=-6.128664\n",
      "[LightGBM] [Info] Start training from score -6.128664\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[I 2023-11-07 01:15:58,275] Trial 26 finished with value: 0.9385854211382731 and parameters: {'num_leaves': 255, 'lambda_l1': 0.1738133344957411, 'lambda_l2': 0.0025653731357764423, 'feature_fraction': 0.44741122000984157, 'min_child_samples': 100, 'learning_rate': 9.027115829575498e-08, 'max_depth': 149, 'num_boost_round': 201}. Best is trial 18 with value: 0.9388526095187443.\n",
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1073, number of negative: 492317\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.085062 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12732\n",
      "[LightGBM] [Info] Number of data points in the train set: 493390, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002175 -> initscore=-6.128664\n",
      "[LightGBM] [Info] Start training from score -6.128664\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[I 2023-11-07 01:16:08,530] Trial 27 finished with value: 0.9337377881614021 and parameters: {'num_leaves': 221, 'lambda_l1': 0.16152883237573237, 'lambda_l2': 0.002416542718210642, 'feature_fraction': 0.4662623823853872, 'min_child_samples': 100, 'learning_rate': 5.606304172771565e-08, 'max_depth': 148, 'num_boost_round': 202}. Best is trial 18 with value: 0.9388526095187443.\n",
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1073, number of negative: 492317\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.085327 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12732\n",
      "[LightGBM] [Info] Number of data points in the train set: 493390, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002175 -> initscore=-6.128664\n",
      "[LightGBM] [Info] Start training from score -6.128664\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[I 2023-11-07 01:16:14,705] Trial 28 finished with value: 0.930245977928467 and parameters: {'num_leaves': 192, 'lambda_l1': 2.4188567758617197, 'lambda_l2': 0.04278620070798456, 'feature_fraction': 0.533111572788714, 'min_child_samples': 91, 'learning_rate': 2.8954429542313793e-06, 'max_depth': 100, 'num_boost_round': 127}. Best is trial 18 with value: 0.9388526095187443.\n",
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1073, number of negative: 492317\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.086013 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12732\n",
      "[LightGBM] [Info] Number of data points in the train set: 493390, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002175 -> initscore=-6.128664\n",
      "[LightGBM] [Info] Start training from score -6.128664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[I 2023-11-07 01:16:27,907] Trial 29 finished with value: 0.9378611000310243 and parameters: {'num_leaves': 235, 'lambda_l1': 1.789863893246008, 'lambda_l2': 0.0017296746024199727, 'feature_fraction': 0.43110217520574234, 'min_child_samples': 76, 'learning_rate': 2.9022876054278965e-07, 'max_depth': 156, 'num_boost_round': 267}. Best is trial 18 with value: 0.9388526095187443.\n",
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1073, number of negative: 492317\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.082107 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12732\n",
      "[LightGBM] [Info] Number of data points in the train set: 493390, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002175 -> initscore=-6.128664\n",
      "[LightGBM] [Info] Start training from score -6.128664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[I 2023-11-07 01:16:41,648] Trial 30 finished with value: 0.9376878707871927 and parameters: {'num_leaves': 233, 'lambda_l1': 0.013293276803314068, 'lambda_l2': 0.0017101661056903813, 'feature_fraction': 0.5040755428493046, 'min_child_samples': 56, 'learning_rate': 2.2682547911951835e-07, 'max_depth': 159, 'num_boost_round': 327}. Best is trial 18 with value: 0.9388526095187443.\n",
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1073, number of negative: 492317\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.074082 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12732\n",
      "[LightGBM] [Info] Number of data points in the train set: 493390, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002175 -> initscore=-6.128664\n",
      "[LightGBM] [Info] Start training from score -6.128664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[I 2023-11-07 01:16:55,562] Trial 31 finished with value: 0.9363876384219424 and parameters: {'num_leaves': 235, 'lambda_l1': 0.01502910075695273, 'lambda_l2': 0.001965502496181559, 'feature_fraction': 0.48251738401419453, 'min_child_samples': 54, 'learning_rate': 2.1399724562489522e-07, 'max_depth': 155, 'num_boost_round': 338}. Best is trial 18 with value: 0.9388526095187443.\n",
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1073, number of negative: 492317\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.071185 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12732\n",
      "[LightGBM] [Info] Number of data points in the train set: 493390, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002175 -> initscore=-6.128664\n",
      "[LightGBM] [Info] Start training from score -6.128664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[I 2023-11-07 01:17:10,283] Trial 32 finished with value: 0.9401237170842276 and parameters: {'num_leaves': 223, 'lambda_l1': 0.2127264038884955, 'lambda_l2': 0.00011549862632306055, 'feature_fraction': 0.4366475234165338, 'min_child_samples': 62, 'learning_rate': 4.050646218822478e-08, 'max_depth': 138, 'num_boost_round': 327}. Best is trial 32 with value: 0.9401237170842276.\n",
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1073, number of negative: 492317\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.077177 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12732\n",
      "[LightGBM] [Info] Number of data points in the train set: 493390, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002175 -> initscore=-6.128664\n",
      "[LightGBM] [Info] Start training from score -6.128664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[I 2023-11-07 01:17:22,399] Trial 33 finished with value: 0.9375383212718674 and parameters: {'num_leaves': 213, 'lambda_l1': 0.09705599432171282, 'lambda_l2': 0.00012324601227205434, 'feature_fraction': 0.4401366501851471, 'min_child_samples': 62, 'learning_rate': 4.241961816114934e-08, 'max_depth': 130, 'num_boost_round': 270}. Best is trial 32 with value: 0.9401237170842276.\n",
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1073, number of negative: 492317\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.103239 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12732\n",
      "[LightGBM] [Info] Number of data points in the train set: 493390, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002175 -> initscore=-6.128664\n",
      "[LightGBM] [Info] Start training from score -6.128664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[I 2023-11-07 01:17:35,941] Trial 34 finished with value: 0.9237949614096402 and parameters: {'num_leaves': 178, 'lambda_l1': 2.211019277630534, 'lambda_l2': 2.7413491404780697e-05, 'feature_fraction': 0.6002245039093528, 'min_child_samples': 76, 'learning_rate': 3.237277094228671e-08, 'max_depth': 51, 'num_boost_round': 269}. Best is trial 32 with value: 0.9401237170842276.\n",
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1073, number of negative: 492317\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018241 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12732\n",
      "[LightGBM] [Info] Number of data points in the train set: 493390, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002175 -> initscore=-6.128664\n",
      "[LightGBM] [Info] Start training from score -6.128664\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[I 2023-11-07 01:17:43,419] Trial 35 finished with value: 0.9187387062257425 and parameters: {'num_leaves': 222, 'lambda_l1': 0.7664747386769656, 'lambda_l2': 0.0006280151610386765, 'feature_fraction': 0.5505259713825458, 'min_child_samples': 61, 'learning_rate': 1.0298664113622029e-08, 'max_depth': 5, 'num_boost_round': 207}. Best is trial 32 with value: 0.9401237170842276.\n",
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1073, number of negative: 492317\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010799 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12732\n",
      "[LightGBM] [Info] Number of data points in the train set: 493390, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002175 -> initscore=-6.128664\n",
      "[LightGBM] [Info] Start training from score -6.128664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[I 2023-11-07 01:17:59,442] Trial 36 finished with value: 0.9410963587668812 and parameters: {'num_leaves': 197, 'lambda_l1': 0.1330732726248773, 'lambda_l2': 0.0001798844809445169, 'feature_fraction': 0.400792257496224, 'min_child_samples': 72, 'learning_rate': 8.38452299446434e-08, 'max_depth': 135, 'num_boost_round': 319}. Best is trial 36 with value: 0.9410963587668812.\n",
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1073, number of negative: 492317\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.066195 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12732\n",
      "[LightGBM] [Info] Number of data points in the train set: 493390, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002175 -> initscore=-6.128664\n",
      "[LightGBM] [Info] Start training from score -6.128664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[I 2023-11-07 01:18:12,589] Trial 37 finished with value: 0.9363573739560975 and parameters: {'num_leaves': 195, 'lambda_l1': 0.10977852149047979, 'lambda_l2': 0.00015938807540111805, 'feature_fraction': 0.4059130559783766, 'min_child_samples': 48, 'learning_rate': 2.699315397370288e-08, 'max_depth': 134, 'num_boost_round': 335}. Best is trial 36 with value: 0.9410963587668812.\n",
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1073, number of negative: 492317\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.082258 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12732\n",
      "[LightGBM] [Info] Number of data points in the train set: 493390, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002175 -> initscore=-6.128664\n",
      "[LightGBM] [Info] Start training from score -6.128664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[I 2023-11-07 01:18:32,622] Trial 38 finished with value: 0.9383144338708758 and parameters: {'num_leaves': 243, 'lambda_l1': 0.13415315251434204, 'lambda_l2': 3.368438158399052e-05, 'feature_fraction': 0.4760500883857026, 'min_child_samples': 73, 'learning_rate': 5.87649403124866e-08, 'max_depth': 100, 'num_boost_round': 427}. Best is trial 36 with value: 0.9410963587668812.\n",
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1073, number of negative: 492317\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.085918 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12732\n",
      "[LightGBM] [Info] Number of data points in the train set: 493390, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002175 -> initscore=-6.128664\n",
      "[LightGBM] [Info] Start training from score -6.128664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[I 2023-11-07 01:18:48,194] Trial 39 finished with value: 0.9260221221848665 and parameters: {'num_leaves': 206, 'lambda_l1': 0.03810377729704542, 'lambda_l2': 0.00018487922710291714, 'feature_fraction': 0.5267338561516253, 'min_child_samples': 63, 'learning_rate': 6.18840664353993e-06, 'max_depth': 95, 'num_boost_round': 318}. Best is trial 36 with value: 0.9410963587668812.\n",
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1073, number of negative: 492317\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.080821 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12732\n",
      "[LightGBM] [Info] Number of data points in the train set: 493390, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002175 -> initscore=-6.128664\n",
      "[LightGBM] [Info] Start training from score -6.128664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[I 2023-11-07 01:19:08,527] Trial 40 finished with value: 0.9264255639764215 and parameters: {'num_leaves': 173, 'lambda_l1': 0.00275235100394784, 'lambda_l2': 1.5140458589209142e-05, 'feature_fraction': 0.5982821471098163, 'min_child_samples': 36, 'learning_rate': 8.523155447926632e-07, 'max_depth': 136, 'num_boost_round': 400}. Best is trial 36 with value: 0.9410963587668812.\n",
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1073, number of negative: 492317\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.085754 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12732\n",
      "[LightGBM] [Info] Number of data points in the train set: 493390, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002175 -> initscore=-6.128664\n",
      "[LightGBM] [Info] Start training from score -6.128664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[I 2023-11-07 01:19:31,375] Trial 41 finished with value: 0.9378941503472816 and parameters: {'num_leaves': 238, 'lambda_l1': 0.5604673482492252, 'lambda_l2': 6.855766610171467e-05, 'feature_fraction': 0.4665210972885945, 'min_child_samples': 71, 'learning_rate': 6.725921090632654e-08, 'max_depth': 101, 'num_boost_round': 444}. Best is trial 36 with value: 0.9410963587668812.\n",
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1073, number of negative: 492317\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.092222 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12732\n",
      "[LightGBM] [Info] Number of data points in the train set: 493390, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002175 -> initscore=-6.128664\n",
      "[LightGBM] [Info] Start training from score -6.128664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[I 2023-11-07 01:19:51,936] Trial 42 finished with value: 0.9408880531337651 and parameters: {'num_leaves': 242, 'lambda_l1': 0.18156442137452972, 'lambda_l2': 0.0002778290454864186, 'feature_fraction': 0.4292146586578942, 'min_child_samples': 66, 'learning_rate': 8.984831072355402e-08, 'max_depth': 82, 'num_boost_round': 436}. Best is trial 36 with value: 0.9410963587668812.\n",
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1073, number of negative: 492317\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.075789 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12732\n",
      "[LightGBM] [Info] Number of data points in the train set: 493390, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002175 -> initscore=-6.128664\n",
      "[LightGBM] [Info] Start training from score -6.128664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[I 2023-11-07 01:20:12,662] Trial 43 finished with value: 0.9393145541689618 and parameters: {'num_leaves': 216, 'lambda_l1': 0.04657766001276493, 'lambda_l2': 0.0003632195930843768, 'feature_fraction': 0.4231201253316375, 'min_child_samples': 59, 'learning_rate': 1.1840953186802787e-07, 'max_depth': 60, 'num_boost_round': 488}. Best is trial 36 with value: 0.9410963587668812.\n",
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1073, number of negative: 492317\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.068305 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12732\n",
      "[LightGBM] [Info] Number of data points in the train set: 493390, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002175 -> initscore=-6.128664\n",
      "[LightGBM] [Info] Start training from score -6.128664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[I 2023-11-07 01:20:37,524] Trial 44 finished with value: 0.9408330959029004 and parameters: {'num_leaves': 223, 'lambda_l1': 0.06233017135647974, 'lambda_l2': 0.0005301311978681211, 'feature_fraction': 0.4219084913182089, 'min_child_samples': 49, 'learning_rate': 2.5181290627635504e-08, 'max_depth': 54, 'num_boost_round': 467}. Best is trial 36 with value: 0.9410963587668812.\n",
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1073, number of negative: 492317\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.112978 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12732\n",
      "[LightGBM] [Info] Number of data points in the train set: 493390, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002175 -> initscore=-6.128664\n",
      "[LightGBM] [Info] Start training from score -6.128664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[I 2023-11-07 01:21:03,179] Trial 45 finished with value: 0.9365521302258438 and parameters: {'num_leaves': 198, 'lambda_l1': 0.05484382212702355, 'lambda_l2': 0.0003917064436858971, 'feature_fraction': 0.4188803691870016, 'min_child_samples': 51, 'learning_rate': 5.838954722043776e-07, 'max_depth': 54, 'num_boost_round': 498}. Best is trial 36 with value: 0.9410963587668812.\n",
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1073, number of negative: 492317\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.087609 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12732\n",
      "[LightGBM] [Info] Number of data points in the train set: 493390, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002175 -> initscore=-6.128664\n",
      "[LightGBM] [Info] Start training from score -6.128664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[I 2023-11-07 01:21:23,945] Trial 46 finished with value: 0.941176768540151 and parameters: {'num_leaves': 225, 'lambda_l1': 0.0004259884130006764, 'lambda_l2': 0.00022180323821718867, 'feature_fraction': 0.40943228351404837, 'min_child_samples': 57, 'learning_rate': 2.702594623574193e-07, 'max_depth': 76, 'num_boost_round': 463}. Best is trial 46 with value: 0.941176768540151.\n",
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1073, number of negative: 492317\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.068150 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12732\n",
      "[LightGBM] [Info] Number of data points in the train set: 493390, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002175 -> initscore=-6.128664\n",
      "[LightGBM] [Info] Start training from score -6.128664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[I 2023-11-07 01:21:42,018] Trial 47 finished with value: 0.9381171450098454 and parameters: {'num_leaves': 189, 'lambda_l1': 0.0016362298306351933, 'lambda_l2': 1.012527587417353e-05, 'feature_fraction': 0.4135564260050726, 'min_child_samples': 43, 'learning_rate': 2.7199097911990278e-08, 'max_depth': 80, 'num_boost_round': 458}. Best is trial 46 with value: 0.941176768540151.\n",
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1073, number of negative: 492317\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.083001 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12732\n",
      "[LightGBM] [Info] Number of data points in the train set: 493390, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002175 -> initscore=-6.128664\n",
      "[LightGBM] [Info] Start training from score -6.128664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[I 2023-11-07 01:22:00,984] Trial 48 finished with value: 0.9247773535687377 and parameters: {'num_leaves': 222, 'lambda_l1': 0.0006056984916953233, 'lambda_l2': 7.643578139781896e-05, 'feature_fraction': 0.4074859180395362, 'min_child_samples': 64, 'learning_rate': 8.335898694666499e-05, 'max_depth': 36, 'num_boost_round': 457}. Best is trial 46 with value: 0.941176768540151.\n",
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1073, number of negative: 492317\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.095153 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12732\n",
      "[LightGBM] [Info] Number of data points in the train set: 493390, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002175 -> initscore=-6.128664\n",
      "[LightGBM] [Info] Start training from score -6.128664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[I 2023-11-07 01:22:18,543] Trial 49 finished with value: 0.9354237341792189 and parameters: {'num_leaves': 226, 'lambda_l1': 8.94625991447684e-05, 'lambda_l2': 0.00019947125302892323, 'feature_fraction': 0.5014042004961861, 'min_child_samples': 37, 'learning_rate': 3.628336335900462e-07, 'max_depth': 39, 'num_boost_round': 373}. Best is trial 46 with value: 0.941176768540151.\n",
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1073, number of negative: 492317\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.083817 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12732\n",
      "[LightGBM] [Info] Number of data points in the train set: 493390, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002175 -> initscore=-6.128664\n",
      "[LightGBM] [Info] Start training from score -6.128664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[I 2023-11-07 01:22:33,186] Trial 50 finished with value: 0.9308154310786939 and parameters: {'num_leaves': 119, 'lambda_l1': 0.022958486086802003, 'lambda_l2': 2.807446739804824e-06, 'feature_fraction': 0.4731559221220298, 'min_child_samples': 66, 'learning_rate': 3.264884810699258e-08, 'max_depth': 73, 'num_boost_round': 421}. Best is trial 46 with value: 0.941176768540151.\n",
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1073, number of negative: 492317\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.081048 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12732\n",
      "[LightGBM] [Info] Number of data points in the train set: 493390, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002175 -> initscore=-6.128664\n",
      "[LightGBM] [Info] Start training from score -6.128664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[I 2023-11-07 01:22:54,170] Trial 51 finished with value: 0.9394533401713298 and parameters: {'num_leaves': 209, 'lambda_l1': 0.008524964470045615, 'lambda_l2': 0.0007399952151589822, 'feature_fraction': 0.42443014404619156, 'min_child_samples': 59, 'learning_rate': 1.4827421851816843e-07, 'max_depth': 58, 'num_boost_round': 472}. Best is trial 46 with value: 0.941176768540151.\n",
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1073, number of negative: 492317\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.087329 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12732\n",
      "[LightGBM] [Info] Number of data points in the train set: 493390, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002175 -> initscore=-6.128664\n",
      "[LightGBM] [Info] Start training from score -6.128664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[I 2023-11-07 01:23:13,765] Trial 52 finished with value: 0.9398569085924491 and parameters: {'num_leaves': 207, 'lambda_l1': 0.006670527287705363, 'lambda_l2': 0.00018608498704673267, 'feature_fraction': 0.40364392722505954, 'min_child_samples': 57, 'learning_rate': 1.904049382151417e-07, 'max_depth': 20, 'num_boost_round': 476}. Best is trial 46 with value: 0.941176768540151.\n",
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1073, number of negative: 492317\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.035926 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12732\n",
      "[LightGBM] [Info] Number of data points in the train set: 493390, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002175 -> initscore=-6.128664\n",
      "[LightGBM] [Info] Start training from score -6.128664\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[I 2023-11-07 01:23:25,966] Trial 53 finished with value: 0.9286767843688466 and parameters: {'num_leaves': 172, 'lambda_l1': 0.005465019037910832, 'lambda_l2': 0.00019871155295522633, 'feature_fraction': 0.4058257673147316, 'min_child_samples': 50, 'learning_rate': 4.272402737798218e-07, 'max_depth': 4, 'num_boost_round': 439}. Best is trial 46 with value: 0.941176768540151.\n",
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1073, number of negative: 492317\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.076488 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12732\n",
      "[LightGBM] [Info] Number of data points in the train set: 493390, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002175 -> initscore=-6.128664\n",
      "[LightGBM] [Info] Start training from score -6.128664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[I 2023-11-07 01:23:45,136] Trial 54 finished with value: 0.9373777549844562 and parameters: {'num_leaves': 186, 'lambda_l1': 0.022969050101076034, 'lambda_l2': 8.82408917826804e-05, 'feature_fraction': 0.4603201647729634, 'min_child_samples': 56, 'learning_rate': 2.085927991420043e-08, 'max_depth': 15, 'num_boost_round': 404}. Best is trial 46 with value: 0.941176768540151.\n",
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1073, number of negative: 492317\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.087311 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12732\n",
      "[LightGBM] [Info] Number of data points in the train set: 493390, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002175 -> initscore=-6.128664\n",
      "[LightGBM] [Info] Start training from score -6.128664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[I 2023-11-07 01:23:59,336] Trial 55 finished with value: 0.9285169778588207 and parameters: {'num_leaves': 67, 'lambda_l1': 0.07081546590109881, 'lambda_l2': 4.209466622476868e-05, 'feature_fraction': 0.43806559626478625, 'min_child_samples': 47, 'learning_rate': 1.3001760868781059e-06, 'max_depth': 28, 'num_boost_round': 478}. Best is trial 46 with value: 0.941176768540151.\n",
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1073, number of negative: 492317\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.091171 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12732\n",
      "[LightGBM] [Info] Number of data points in the train set: 493390, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002175 -> initscore=-6.128664\n",
      "[LightGBM] [Info] Start training from score -6.128664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[I 2023-11-07 01:24:15,506] Trial 56 finished with value: 0.932675619376856 and parameters: {'num_leaves': 200, 'lambda_l1': 0.002482816499075284, 'lambda_l2': 0.0007718166387350355, 'feature_fraction': 0.4856597497844914, 'min_child_samples': 41, 'learning_rate': 7.599513968550018e-08, 'max_depth': 110, 'num_boost_round': 353}. Best is trial 46 with value: 0.941176768540151.\n",
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1073, number of negative: 492317\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.081543 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12732\n",
      "[LightGBM] [Info] Number of data points in the train set: 493390, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002175 -> initscore=-6.128664\n",
      "[LightGBM] [Info] Start training from score -6.128664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[I 2023-11-07 01:24:34,279] Trial 57 finished with value: 0.9411851260913886 and parameters: {'num_leaves': 243, 'lambda_l1': 0.000805308659712021, 'lambda_l2': 0.0002701929566070315, 'feature_fraction': 0.4021835445152153, 'min_child_samples': 66, 'learning_rate': 1.9493709730866725e-08, 'max_depth': 86, 'num_boost_round': 466}. Best is trial 57 with value: 0.9411851260913886.\n",
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1073, number of negative: 492317\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.085522 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12732\n",
      "[LightGBM] [Info] Number of data points in the train set: 493390, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002175 -> initscore=-6.128664\n",
      "[LightGBM] [Info] Start training from score -6.128664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[I 2023-11-07 01:24:50,403] Trial 58 finished with value: 0.9404770135683578 and parameters: {'num_leaves': 231, 'lambda_l1': 0.0006298487994166837, 'lambda_l2': 1.3089876486820649e-05, 'feature_fraction': 0.43100934951396863, 'min_child_samples': 68, 'learning_rate': 1.6585866861805576e-08, 'max_depth': 91, 'num_boost_round': 382}. Best is trial 57 with value: 0.9411851260913886.\n",
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1073, number of negative: 492317\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.079964 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12732\n",
      "[LightGBM] [Info] Number of data points in the train set: 493390, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002175 -> initscore=-6.128664\n",
      "[LightGBM] [Info] Start training from score -6.128664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[I 2023-11-07 01:25:07,268] Trial 59 finished with value: 0.9397216682178788 and parameters: {'num_leaves': 243, 'lambda_l1': 0.0006072928805536051, 'lambda_l2': 1.6733388124976264e-05, 'feature_fraction': 0.4580524125043559, 'min_child_samples': 66, 'learning_rate': 1.9689005347244247e-08, 'max_depth': 87, 'num_boost_round': 378}. Best is trial 57 with value: 0.9411851260913886.\n",
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1073, number of negative: 492317\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.069369 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12732\n",
      "[LightGBM] [Info] Number of data points in the train set: 493390, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002175 -> initscore=-6.128664\n",
      "[LightGBM] [Info] Start training from score -6.128664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[I 2023-11-07 01:25:25,324] Trial 60 finished with value: 0.9399156647102399 and parameters: {'num_leaves': 242, 'lambda_l1': 0.00022400792333007166, 'lambda_l2': 8.210481309239644e-06, 'feature_fraction': 0.4241632890475543, 'min_child_samples': 79, 'learning_rate': 1.492450669201592e-08, 'max_depth': 71, 'num_boost_round': 409}. Best is trial 57 with value: 0.9411851260913886.\n",
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1073, number of negative: 492317\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.084034 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12732\n",
      "[LightGBM] [Info] Number of data points in the train set: 493390, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002175 -> initscore=-6.128664\n",
      "[LightGBM] [Info] Start training from score -6.128664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[I 2023-11-07 01:25:44,270] Trial 61 finished with value: 0.9391743752413877 and parameters: {'num_leaves': 227, 'lambda_l1': 9.725775104213076e-05, 'lambda_l2': 5.736052508584888e-05, 'feature_fraction': 0.43814631210360705, 'min_child_samples': 73, 'learning_rate': 5.4563666412859056e-08, 'max_depth': 120, 'num_boost_round': 449}. Best is trial 57 with value: 0.9411851260913886.\n",
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1073, number of negative: 492317\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.080817 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12732\n",
      "[LightGBM] [Info] Number of data points in the train set: 493390, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002175 -> initscore=-6.128664\n",
      "[LightGBM] [Info] Start training from score -6.128664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[I 2023-11-07 01:26:01,428] Trial 62 finished with value: 0.9405172817697748 and parameters: {'num_leaves': 228, 'lambda_l1': 0.0010725585041716649, 'lambda_l2': 0.0009372965631876965, 'feature_fraction': 0.4472248628315087, 'min_child_samples': 68, 'learning_rate': 4.366108686475287e-08, 'max_depth': 89, 'num_boost_round': 386}. Best is trial 57 with value: 0.9411851260913886.\n",
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1073, number of negative: 492317\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.074099 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12732\n",
      "[LightGBM] [Info] Number of data points in the train set: 493390, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002175 -> initscore=-6.128664\n",
      "[LightGBM] [Info] Start training from score -6.128664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[I 2023-11-07 01:26:18,325] Trial 63 finished with value: 0.9439727493177832 and parameters: {'num_leaves': 246, 'lambda_l1': 0.00046561209207286725, 'lambda_l2': 0.0008968676583226133, 'feature_fraction': 0.4002978583855602, 'min_child_samples': 67, 'learning_rate': 1.0289507953635367e-08, 'max_depth': 88, 'num_boost_round': 388}. Best is trial 63 with value: 0.9439727493177832.\n",
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1073, number of negative: 492317\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.083277 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12732\n",
      "[LightGBM] [Info] Number of data points in the train set: 493390, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002175 -> initscore=-6.128664\n",
      "[LightGBM] [Info] Start training from score -6.128664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[I 2023-11-07 01:26:37,468] Trial 64 finished with value: 0.9399602383168398 and parameters: {'num_leaves': 243, 'lambda_l1': 0.0013218720862166683, 'lambda_l2': 0.0009625072521336814, 'feature_fraction': 0.4564251517452632, 'min_child_samples': 66, 'learning_rate': 1.2123701269740442e-07, 'max_depth': 47, 'num_boost_round': 436}. Best is trial 63 with value: 0.9439727493177832.\n",
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1073, number of negative: 492317\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.086172 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12732\n",
      "[LightGBM] [Info] Number of data points in the train set: 493390, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002175 -> initscore=-6.128664\n",
      "[LightGBM] [Info] Start training from score -6.128664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[I 2023-11-07 01:26:52,444] Trial 65 finished with value: 0.9378032303201829 and parameters: {'num_leaves': 147, 'lambda_l1': 3.6931706273707564e-05, 'lambda_l2': 0.0044734289731244645, 'feature_fraction': 0.40019941804052145, 'min_child_samples': 53, 'learning_rate': 1.0365498289461849e-08, 'max_depth': 80, 'num_boost_round': 460}. Best is trial 63 with value: 0.9439727493177832.\n",
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1073, number of negative: 492317\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.069204 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12732\n",
      "[LightGBM] [Info] Number of data points in the train set: 493390, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002175 -> initscore=-6.128664\n",
      "[LightGBM] [Info] Start training from score -6.128664\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[I 2023-11-07 01:27:13,190] Trial 66 finished with value: 0.9336475012821244 and parameters: {'num_leaves': 247, 'lambda_l1': 0.0011594224798353939, 'lambda_l2': 0.00025888671093911926, 'feature_fraction': 0.4900491611449175, 'min_child_samples': 74, 'learning_rate': 3.8757256105404293e-08, 'max_depth': 65, 'num_boost_round': 429}. Best is trial 63 with value: 0.9439727493177832.\n",
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1073, number of negative: 492317\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.069845 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12732\n",
      "[LightGBM] [Info] Number of data points in the train set: 493390, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002175 -> initscore=-6.128664\n",
      "[LightGBM] [Info] Start training from score -6.128664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[I 2023-11-07 01:27:23,713] Trial 67 finished with value: 0.9194670161642639 and parameters: {'num_leaves': 27, 'lambda_l1': 0.0003904400777018503, 'lambda_l2': 0.0012119906058823127, 'feature_fraction': 0.5110903486059232, 'min_child_samples': 80, 'learning_rate': 2.983443871454858e-07, 'max_depth': 106, 'num_boost_round': 414}. Best is trial 63 with value: 0.9439727493177832.\n",
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1073, number of negative: 492317\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.076429 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12732\n",
      "[LightGBM] [Info] Number of data points in the train set: 493390, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002175 -> initscore=-6.128664\n",
      "[LightGBM] [Info] Start training from score -6.128664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[I 2023-11-07 01:27:39,685] Trial 68 finished with value: 0.9398505771142388 and parameters: {'num_leaves': 218, 'lambda_l1': 0.0032788074822027134, 'lambda_l2': 0.008012529312354945, 'feature_fraction': 0.4503374856325862, 'min_child_samples': 69, 'learning_rate': 9.55683359841842e-08, 'max_depth': 74, 'num_boost_round': 361}. Best is trial 63 with value: 0.9439727493177832.\n",
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1073, number of negative: 492317\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.086946 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12732\n",
      "[LightGBM] [Info] Number of data points in the train set: 493390, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002175 -> initscore=-6.128664\n",
      "[LightGBM] [Info] Start training from score -6.128664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[I 2023-11-07 01:27:56,704] Trial 69 finished with value: 0.9394844910441241 and parameters: {'num_leaves': 232, 'lambda_l1': 0.00032799011268539, 'lambda_l2': 0.00048704709026216135, 'feature_fraction': 0.475069307813637, 'min_child_samples': 58, 'learning_rate': 1.8104126846663464e-08, 'max_depth': 117, 'num_boost_round': 391}. Best is trial 63 with value: 0.9439727493177832.\n",
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1073, number of negative: 492317\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.069981 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12732\n",
      "[LightGBM] [Info] Number of data points in the train set: 493390, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002175 -> initscore=-6.128664\n",
      "[LightGBM] [Info] Start training from score -6.128664\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[I 2023-11-07 01:28:18,902] Trial 70 finished with value: 0.9394825916006609 and parameters: {'num_leaves': 254, 'lambda_l1': 0.0014595981101843357, 'lambda_l2': 0.0003994334807187979, 'feature_fraction': 0.422796116808418, 'min_child_samples': 84, 'learning_rate': 4.577858147227575e-08, 'max_depth': 43, 'num_boost_round': 498}. Best is trial 63 with value: 0.9439727493177832.\n",
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1073, number of negative: 492317\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.086436 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12732\n",
      "[LightGBM] [Info] Number of data points in the train set: 493390, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002175 -> initscore=-6.128664\n",
      "[LightGBM] [Info] Start training from score -6.128664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[I 2023-11-07 01:28:35,925] Trial 71 finished with value: 0.9400288715406386 and parameters: {'num_leaves': 228, 'lambda_l1': 0.000539877542643888, 'lambda_l2': 0.0008952120268715831, 'feature_fraction': 0.42656248132375457, 'min_child_samples': 67, 'learning_rate': 2.092227825875205e-08, 'max_depth': 94, 'num_boost_round': 383}. Best is trial 63 with value: 0.9439727493177832.\n",
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1073, number of negative: 492317\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.082929 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12732\n",
      "[LightGBM] [Info] Number of data points in the train set: 493390, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002175 -> initscore=-6.128664\n",
      "[LightGBM] [Info] Start training from score -6.128664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[I 2023-11-07 01:28:50,357] Trial 72 finished with value: 0.9436516167429609 and parameters: {'num_leaves': 232, 'lambda_l1': 0.0009359839790468504, 'lambda_l2': 0.0001225906115105651, 'feature_fraction': 0.40076745048322054, 'min_child_samples': 69, 'learning_rate': 1.8794022488195092e-08, 'max_depth': 88, 'num_boost_round': 352}. Best is trial 63 with value: 0.9439727493177832.\n",
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1073, number of negative: 492317\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012150 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 12732\n",
      "[LightGBM] [Info] Number of data points in the train set: 493390, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002175 -> initscore=-6.128664\n",
      "[LightGBM] [Info] Start training from score -6.128664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[I 2023-11-07 01:29:07,769] Trial 73 finished with value: 0.9431390202670616 and parameters: {'num_leaves': 247, 'lambda_l1': 0.0009971831804845947, 'lambda_l2': 0.0003292018604708089, 'feature_fraction': 0.40175285272618866, 'min_child_samples': 71, 'learning_rate': 1.4715815066302652e-07, 'max_depth': 86, 'num_boost_round': 310}. Best is trial 63 with value: 0.9439727493177832.\n",
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1073, number of negative: 492317\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.089694 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12732\n",
      "[LightGBM] [Info] Number of data points in the train set: 493390, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002175 -> initscore=-6.128664\n",
      "[LightGBM] [Info] Start training from score -6.128664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[I 2023-11-07 01:29:21,942] Trial 74 finished with value: 0.9386431642195504 and parameters: {'num_leaves': 247, 'lambda_l1': 0.003099878517565526, 'lambda_l2': 0.00011439801118243181, 'feature_fraction': 0.40196278646302386, 'min_child_samples': 73, 'learning_rate': 2.1617663343605178e-07, 'max_depth': 64, 'num_boost_round': 295}. Best is trial 63 with value: 0.9439727493177832.\n",
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1073, number of negative: 492317\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.081908 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12732\n",
      "[LightGBM] [Info] Number of data points in the train set: 493390, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002175 -> initscore=-6.128664\n",
      "[LightGBM] [Info] Start training from score -6.128664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[I 2023-11-07 01:29:36,255] Trial 75 finished with value: 0.9402165365547894 and parameters: {'num_leaves': 239, 'lambda_l1': 0.00018623613718778625, 'lambda_l2': 0.00035091501450684905, 'feature_fraction': 0.41647487159144947, 'min_child_samples': 64, 'learning_rate': 1.01503052173996e-07, 'max_depth': 81, 'num_boost_round': 312}. Best is trial 63 with value: 0.9439727493177832.\n",
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1073, number of negative: 492317\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.067163 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12732\n",
      "[LightGBM] [Info] Number of data points in the train set: 493390, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002175 -> initscore=-6.128664\n",
      "[LightGBM] [Info] Start training from score -6.128664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[I 2023-11-07 01:29:52,036] Trial 76 finished with value: 0.9431396534148828 and parameters: {'num_leaves': 256, 'lambda_l1': 0.007143094380427369, 'lambda_l2': 0.0002461800271096744, 'feature_fraction': 0.4001386075880738, 'min_child_samples': 60, 'learning_rate': 1.0265615948846526e-08, 'max_depth': 113, 'num_boost_round': 349}. Best is trial 63 with value: 0.9439727493177832.\n",
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1073, number of negative: 492317\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.083965 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12732\n",
      "[LightGBM] [Info] Number of data points in the train set: 493390, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002175 -> initscore=-6.128664\n",
      "[LightGBM] [Info] Start training from score -6.128664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[I 2023-11-07 01:30:08,472] Trial 77 finished with value: 0.943196130200518 and parameters: {'num_leaves': 247, 'lambda_l1': 0.006279643587593205, 'lambda_l2': 3.6610114945661574e-05, 'feature_fraction': 0.40054866467530204, 'min_child_samples': 60, 'learning_rate': 1.01163252647666e-08, 'max_depth': 125, 'num_boost_round': 358}. Best is trial 63 with value: 0.9439727493177832.\n",
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1073, number of negative: 492317\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.083830 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12732\n",
      "[LightGBM] [Info] Number of data points in the train set: 493390, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002175 -> initscore=-6.128664\n",
      "[LightGBM] [Info] Start training from score -6.128664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[I 2023-11-07 01:30:24,914] Trial 78 finished with value: 0.9394394109192674 and parameters: {'num_leaves': 256, 'lambda_l1': 0.005428231967292862, 'lambda_l2': 2.8344974210734926e-05, 'feature_fraction': 0.4479269269658119, 'min_child_samples': 54, 'learning_rate': 1.0116575438371546e-08, 'max_depth': 129, 'num_boost_round': 356}. Best is trial 63 with value: 0.9439727493177832.\n",
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1073, number of negative: 492317\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.085696 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12732\n",
      "[LightGBM] [Info] Number of data points in the train set: 493390, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002175 -> initscore=-6.128664\n",
      "[LightGBM] [Info] Start training from score -6.128664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[I 2023-11-07 01:30:38,062] Trial 79 finished with value: 0.9388014511748057 and parameters: {'num_leaves': 247, 'lambda_l1': 0.009718983981272016, 'lambda_l2': 4.836376722029023e-05, 'feature_fraction': 0.4677790249363994, 'min_child_samples': 60, 'learning_rate': 1.4456893882041564e-08, 'max_depth': 111, 'num_boost_round': 280}. Best is trial 63 with value: 0.9439727493177832.\n",
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1073, number of negative: 492317\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.086529 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12732\n",
      "[LightGBM] [Info] Number of data points in the train set: 493390, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002175 -> initscore=-6.128664\n",
      "[LightGBM] [Info] Start training from score -6.128664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[I 2023-11-07 01:30:52,011] Trial 80 finished with value: 0.938707998556423 and parameters: {'num_leaves': 214, 'lambda_l1': 0.002112077658938693, 'lambda_l2': 0.00011288700410858154, 'feature_fraction': 0.41037507184225286, 'min_child_samples': 70, 'learning_rate': 2.9879112690159105e-08, 'max_depth': 124, 'num_boost_round': 344}. Best is trial 63 with value: 0.9439727493177832.\n",
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1073, number of negative: 492317\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.072639 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12732\n",
      "[LightGBM] [Info] Number of data points in the train set: 493390, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002175 -> initscore=-6.128664\n",
      "[LightGBM] [Info] Start training from score -6.128664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[I 2023-11-07 01:31:05,012] Trial 81 finished with value: 0.9432466553966354 and parameters: {'num_leaves': 237, 'lambda_l1': 0.001018617091776084, 'lambda_l2': 0.00025088706536588934, 'feature_fraction': 0.4004548082587393, 'min_child_samples': 64, 'learning_rate': 6.103844107696536e-08, 'max_depth': 104, 'num_boost_round': 307}. Best is trial 63 with value: 0.9439727493177832.\n",
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1073, number of negative: 492317\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.085903 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12732\n",
      "[LightGBM] [Info] Number of data points in the train set: 493390, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002175 -> initscore=-6.128664\n",
      "[LightGBM] [Info] Start training from score -6.128664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[I 2023-11-07 01:31:18,683] Trial 82 finished with value: 0.9378434985215999 and parameters: {'num_leaves': 236, 'lambda_l1': 0.0009619331357098159, 'lambda_l2': 9.7830679265837e-05, 'feature_fraction': 0.40473287337412417, 'min_child_samples': 77, 'learning_rate': 6.420295654090982e-08, 'max_depth': 113, 'num_boost_round': 310}. Best is trial 63 with value: 0.9439727493177832.\n",
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1073, number of negative: 492317\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.077339 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12732\n",
      "[LightGBM] [Info] Number of data points in the train set: 493390, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002175 -> initscore=-6.128664\n",
      "[LightGBM] [Info] Start training from score -6.128664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[I 2023-11-07 01:31:30,954] Trial 83 finished with value: 0.9430213814019159 and parameters: {'num_leaves': 246, 'lambda_l1': 0.002074943263798403, 'lambda_l2': 0.0002321550621022396, 'feature_fraction': 0.40090658788126793, 'min_child_samples': 63, 'learning_rate': 1.0028755932215388e-08, 'max_depth': 95, 'num_boost_round': 285}. Best is trial 63 with value: 0.9439727493177832.\n",
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1073, number of negative: 492317\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.087995 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12732\n",
      "[LightGBM] [Info] Number of data points in the train set: 493390, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002175 -> initscore=-6.128664\n",
      "[LightGBM] [Info] Start training from score -6.128664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[I 2023-11-07 01:31:44,121] Trial 84 finished with value: 0.9409533939888947 and parameters: {'num_leaves': 249, 'lambda_l1': 0.003981495150423071, 'lambda_l2': 0.00027032222277502296, 'feature_fraction': 0.44378306966805214, 'min_child_samples': 63, 'learning_rate': 1.0981585995834999e-08, 'max_depth': 104, 'num_boost_round': 284}. Best is trial 63 with value: 0.9439727493177832.\n",
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1073, number of negative: 492317\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.084091 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12732\n",
      "[LightGBM] [Info] Number of data points in the train set: 493390, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002175 -> initscore=-6.128664\n",
      "[LightGBM] [Info] Start training from score -6.128664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[I 2023-11-07 01:32:00,961] Trial 85 finished with value: 0.9408990699058509 and parameters: {'num_leaves': 256, 'lambda_l1': 0.002018188802185509, 'lambda_l2': 5.107261262997305e-05, 'feature_fraction': 0.4179271618684515, 'min_child_samples': 61, 'learning_rate': 2.1214177917580377e-08, 'max_depth': 99, 'num_boost_round': 366}. Best is trial 63 with value: 0.9439727493177832.\n",
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1073, number of negative: 492317\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.085864 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12732\n",
      "[LightGBM] [Info] Number of data points in the train set: 493390, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002175 -> initscore=-6.128664\n",
      "[LightGBM] [Info] Start training from score -6.128664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[I 2023-11-07 01:32:12,726] Trial 86 finished with value: 0.9375280642771668 and parameters: {'num_leaves': 235, 'lambda_l1': 0.0007425743762451597, 'lambda_l2': 0.0017550939168559606, 'feature_fraction': 0.43305997600534113, 'min_child_samples': 64, 'learning_rate': 3.594368927661409e-08, 'max_depth': 87, 'num_boost_round': 242}. Best is trial 63 with value: 0.9439727493177832.\n",
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1073, number of negative: 492317\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.081487 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12732\n",
      "[LightGBM] [Info] Number of data points in the train set: 493390, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002175 -> initscore=-6.128664\n",
      "[LightGBM] [Info] Start training from score -6.128664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[I 2023-11-07 01:32:27,284] Trial 87 finished with value: 0.937571624847253 and parameters: {'num_leaves': 249, 'lambda_l1': 0.00036494343204257815, 'lambda_l2': 0.0001396486441837575, 'feature_fraction': 0.46546999743300965, 'min_child_samples': 52, 'learning_rate': 1.01068708637896e-08, 'max_depth': 126, 'num_boost_round': 306}. Best is trial 63 with value: 0.9439727493177832.\n",
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1073, number of negative: 492317\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.075219 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12732\n",
      "[LightGBM] [Info] Number of data points in the train set: 493390, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002175 -> initscore=-6.128664\n",
      "[LightGBM] [Info] Start training from score -6.128664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[I 2023-11-07 01:32:41,284] Trial 88 finished with value: 0.9373487568142533 and parameters: {'num_leaves': 239, 'lambda_l1': 0.0014785027783334648, 'lambda_l2': 0.0005720137881158486, 'feature_fraction': 0.41806296917147817, 'min_child_samples': 17, 'learning_rate': 5.902186621416883e-08, 'max_depth': 94, 'num_boost_round': 333}. Best is trial 63 with value: 0.9439727493177832.\n",
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1073, number of negative: 492317\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.073676 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12732\n",
      "[LightGBM] [Info] Number of data points in the train set: 493390, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002175 -> initscore=-6.128664\n",
      "[LightGBM] [Info] Start training from score -6.128664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[I 2023-11-07 01:32:51,402] Trial 89 finished with value: 0.9419675701686073 and parameters: {'num_leaves': 246, 'lambda_l1': 0.004315261323388023, 'lambda_l2': 6.84075778839696e-05, 'feature_fraction': 0.40137605584324104, 'min_child_samples': 57, 'learning_rate': 1.6161659398392794e-07, 'max_depth': 72, 'num_boost_round': 246}. Best is trial 63 with value: 0.9439727493177832.\n",
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1073, number of negative: 492317\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.083722 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12732\n",
      "[LightGBM] [Info] Number of data points in the train set: 493390, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002175 -> initscore=-6.128664\n",
      "[LightGBM] [Info] Start training from score -6.128664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[I 2023-11-07 01:33:02,787] Trial 90 finished with value: 0.9397865025547515 and parameters: {'num_leaves': 248, 'lambda_l1': 0.004792295636448797, 'lambda_l2': 7.361799439686633e-05, 'feature_fraction': 0.45020485567159335, 'min_child_samples': 45, 'learning_rate': 2.015925038900717e-08, 'max_depth': 69, 'num_boost_round': 255}. Best is trial 63 with value: 0.9439727493177832.\n",
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1073, number of negative: 492317\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.089261 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12732\n",
      "[LightGBM] [Info] Number of data points in the train set: 493390, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002175 -> initscore=-6.128664\n",
      "[LightGBM] [Info] Start training from score -6.128664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[I 2023-11-07 01:33:16,964] Trial 91 finished with value: 0.940348864449383 and parameters: {'num_leaves': 241, 'lambda_l1': 0.010581585704534395, 'lambda_l2': 0.00028454793730891707, 'feature_fraction': 0.4149145381760325, 'min_child_samples': 56, 'learning_rate': 1.3197740814373605e-07, 'max_depth': 77, 'num_boost_round': 349}. Best is trial 63 with value: 0.9439727493177832.\n",
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1073, number of negative: 492317\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.071690 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12732\n",
      "[LightGBM] [Info] Number of data points in the train set: 493390, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002175 -> initscore=-6.128664\n",
      "[LightGBM] [Info] Start training from score -6.128664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[I 2023-11-07 01:33:30,341] Trial 92 finished with value: 0.9426991091610158 and parameters: {'num_leaves': 256, 'lambda_l1': 0.0026419584169625637, 'lambda_l2': 3.8055895943072676e-05, 'feature_fraction': 0.40051093668085563, 'min_child_samples': 59, 'learning_rate': 3.733905567760845e-08, 'max_depth': 106, 'num_boost_round': 325}. Best is trial 63 with value: 0.9439727493177832.\n",
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1073, number of negative: 492317\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.084801 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12732\n",
      "[LightGBM] [Info] Number of data points in the train set: 493390, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002175 -> initscore=-6.128664\n",
      "[LightGBM] [Info] Start training from score -6.128664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[I 2023-11-07 01:33:42,123] Trial 93 finished with value: 0.9421314288246877 and parameters: {'num_leaves': 252, 'lambda_l1': 0.0025833744063690047, 'lambda_l2': 3.767728965308084e-05, 'feature_fraction': 0.4002995514120754, 'min_child_samples': 61, 'learning_rate': 3.1897380542083755e-08, 'max_depth': 107, 'num_boost_round': 286}. Best is trial 63 with value: 0.9439727493177832.\n",
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1073, number of negative: 492317\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.088808 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12732\n",
      "[LightGBM] [Info] Number of data points in the train set: 493390, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002175 -> initscore=-6.128664\n",
      "[LightGBM] [Info] Start training from score -6.128664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[I 2023-11-07 01:33:52,063] Trial 94 finished with value: 0.9381886907136209 and parameters: {'num_leaves': 251, 'lambda_l1': 0.0027076130300550823, 'lambda_l2': 4.1530892961009664e-05, 'feature_fraction': 0.43562041314625655, 'min_child_samples': 59, 'learning_rate': 3.7804080084481145e-08, 'max_depth': 108, 'num_boost_round': 222}. Best is trial 63 with value: 0.9439727493177832.\n",
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1073, number of negative: 492317\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.084119 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12732\n",
      "[LightGBM] [Info] Number of data points in the train set: 493390, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002175 -> initscore=-6.128664\n",
      "[LightGBM] [Info] Start training from score -6.128664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[I 2023-11-07 01:34:03,471] Trial 95 finished with value: 0.9415071450731602 and parameters: {'num_leaves': 232, 'lambda_l1': 0.0037452805927568125, 'lambda_l2': 2.3119571907887245e-05, 'feature_fraction': 0.4007262643804, 'min_child_samples': 62, 'learning_rate': 2.9733634073199448e-08, 'max_depth': 116, 'num_boost_round': 285}. Best is trial 63 with value: 0.9439727493177832.\n",
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1073, number of negative: 492317\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.074749 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12732\n",
      "[LightGBM] [Info] Number of data points in the train set: 493390, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002175 -> initscore=-6.128664\n",
      "[LightGBM] [Info] Start training from score -6.128664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[I 2023-11-07 01:34:17,237] Trial 96 finished with value: 0.9405856617344452 and parameters: {'num_leaves': 256, 'lambda_l1': 0.01429456284797365, 'lambda_l2': 7.887631457493447e-05, 'feature_fraction': 0.4315174010923336, 'min_child_samples': 55, 'learning_rate': 1.4639272031580223e-07, 'max_depth': 98, 'num_boost_round': 323}. Best is trial 63 with value: 0.9439727493177832.\n",
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1073, number of negative: 492317\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.078850 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12732\n",
      "[LightGBM] [Info] Number of data points in the train set: 493390, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002175 -> initscore=-6.128664\n",
      "[LightGBM] [Info] Start training from score -6.128664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[I 2023-11-07 01:34:29,725] Trial 97 finished with value: 0.9377795505916766 and parameters: {'num_leaves': 251, 'lambda_l1': 0.007469541142038923, 'lambda_l2': 3.3664398104371776e-05, 'feature_fraction': 0.41873292816356605, 'min_child_samples': 75, 'learning_rate': 6.308634683478128e-08, 'max_depth': 140, 'num_boost_round': 302}. Best is trial 63 with value: 0.9439727493177832.\n",
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1073, number of negative: 492317\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.087224 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12732\n",
      "[LightGBM] [Info] Number of data points in the train set: 493390, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002175 -> initscore=-6.128664\n",
      "[LightGBM] [Info] Start training from score -6.128664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[I 2023-11-07 01:34:44,299] Trial 98 finished with value: 0.9403791289152278 and parameters: {'num_leaves': 246, 'lambda_l1': 0.0021064041977088468, 'lambda_l2': 0.0001641746100642667, 'feature_fraction': 0.44458046954791597, 'min_child_samples': 71, 'learning_rate': 1.4242737780492596e-08, 'max_depth': 105, 'num_boost_round': 343}. Best is trial 63 with value: 0.9439727493177832.\n",
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1073, number of negative: 492317\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.079479 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12732\n",
      "[LightGBM] [Info] Number of data points in the train set: 493390, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002175 -> initscore=-6.128664\n",
      "[LightGBM] [Info] Start training from score -6.128664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[I 2023-11-07 01:34:55,672] Trial 99 finished with value: 0.939336967601826 and parameters: {'num_leaves': 238, 'lambda_l1': 0.0068234768803643354, 'lambda_l2': 0.00011117962483079194, 'feature_fraction': 0.477103192690751, 'min_child_samples': 60, 'learning_rate': 4.380950572690085e-07, 'max_depth': 122, 'num_boost_round': 254}. Best is trial 63 with value: 0.9439727493177832.\n"
     ]
    }
   ],
   "source": [
    "# WARNING: 2 changes to change evaluation metric\n",
    "optimisation_metric = \"auc\" #\"accuracy\" \"recall\" \"precision\" \"f1\" \"auc\"\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 2, 256),\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc', #\"accuracy\" \"recall\" \"precision\" \"f1\" \"auc\"\n",
    "        'boosting_type': 'gbdt',\n",
    "        'lambda_l1': trial.suggest_float('lambda_l1', 1e-8, 10.0, log=True),\n",
    "        'lambda_l2': trial.suggest_float('lambda_l2', 1e-8, 10.0, log=True),\n",
    "        'feature_fraction': trial.suggest_float('feature_fraction', 0.4, 1.0),\n",
    "        # 'bagging_fraction': trial.suggest_float('bagging_fraction', 0.4, 1.0),\n",
    "        # 'bagging_freq': trial.suggest_int('bagging_freq', 1, 7),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 1e-8, 10.0, log=True),\n",
    "        'scale_pos_weight': 100,\n",
    "        'max_depth': trial.suggest_int('max_depth', 2, 256),\n",
    "        'num_boost_round': trial.suggest_int('num_boost_round', 100, 500),\n",
    "    }\n",
    "    \n",
    "    # full data\n",
    "    gbm = lgb.train(param, lgb.Dataset(x_train, y_train))\n",
    "    \n",
    "    preds = gbm.predict(x_validation)\n",
    "    y_pred_binary = np.round(preds)\n",
    "    \n",
    "    auc = roc_auc_score(y_validation, preds)\n",
    "    accuracy = accuracy_score(y_validation, y_pred_binary)\n",
    "    recall = recall_score(y_validation, y_pred_binary)\n",
    "    precision = precision_score(y_validation, y_pred_binary)\n",
    "    f1 = f1_score(y_validation, y_pred_binary)\n",
    "    \n",
    "    #choose the metric you want to optimized\n",
    "    if optimisation_metric == 'recall': \n",
    "        return recall\n",
    "    elif optimisation_metric == 'precision': \n",
    "        return precision\n",
    "    elif optimisation_metric == 'f1':\n",
    "        return f1\n",
    "    elif optimisation_metric == 'auc':\n",
    "        return auc\n",
    "    elif optimisation_metric == 'accuracy': \n",
    "        return accuracy\n",
    "    return auc\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "best_params = study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\lightgbm\\engine.py:172: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1073, number of negative: 492317\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.082780 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 12732\n",
      "[LightGBM] [Info] Number of data points in the train set: 493390, number of used features: 51\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.002175 -> initscore=-6.128664\n",
      "[LightGBM] [Info] Start training from score -6.128664\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    }
   ],
   "source": [
    "# WARNING: 1 changement to chose evaluation metric, should allign with previous cell\n",
    "best_params['objective'] = 'binary'\n",
    "best_params['metric'] = 'auc' #\"accuracy\" \"recall\" \"precision\" \"f1\" \"auc\"\n",
    "\n",
    "gbm = lgb.train(best_params, lgb.Dataset(x_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = gbm.predict(x_test)\n",
    "y_pred_binary = np.round(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Documents\\Capstone\\.venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1469: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9964612822647794\n",
      "Recall: 0.0\n",
      "Precision: 0.0\n",
      "F1 Score: 0.0\n",
      "AUC: 0.9485290669432594\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x25f2b746290>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred_binary)\n",
    "recall = recall_score(y_test, y_pred_binary)\n",
    "precision = precision_score(y_test, y_pred_binary)\n",
    "f1 = f1_score(y_test, y_pred_binary)\n",
    "auc = roc_auc_score(y_test, y_pred)\n",
    "confusion = confusion_matrix(y_test, y_pred_binary)\n",
    "\n",
    "print('Accuracy:', accuracy)\n",
    "print('Recall:', recall)\n",
    "print('Precision:', precision)\n",
    "print('F1 Score:', f1)\n",
    "print('AUC:', auc)\n",
    "\n",
    "\n",
    "ConfusionMatrixDisplay(confusion).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRAUC:  0.4982306411323897\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import average_precision_score, auc\n",
    "\n",
    "precision2, recall2, threshold = precision_recall_curve(y_test, y_pred_binary)\n",
    "prauc = auc(precision2, recall2)\n",
    "print(\"PRAUC: \", prauc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
