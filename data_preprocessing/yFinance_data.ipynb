{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_data(ticker, _start =dt.date(2000,1,1), _end = dt.date(2023,5,31)):\n",
    "    return yf.download(ticker, start=_start, end = _end)\n",
    "    \n",
    "def calculate_monthly_rsi(df):\n",
    "    df['diff'] = df['Adj Close'].diff(1)\n",
    "    df['gain'] = df['diff'].clip(lower=0).round(2).fillna(0)\n",
    "    df['loss'] = df['diff'].clip(upper=0).abs().round(2).fillna(0)\n",
    "    window_length = 12\n",
    "    df['avg_gain'] = df['gain'].rolling(window=window_length, min_periods=1).mean()[:window_length+1]\n",
    "    df['avg_loss'] = df['loss'].rolling(window=window_length, min_periods=1).mean()[:window_length+1]\n",
    "    for i, row in enumerate(df['avg_gain'].iloc[window_length+1:]):\n",
    "        df['avg_gain'].iloc[i + window_length + 1] =(df['avg_gain'].iloc[i + window_length] *(window_length - 1) +df['gain'].iloc[i + window_length + 1])/ window_length\n",
    "    for i, row in enumerate(df['avg_loss'].iloc[window_length+1:]):\n",
    "        df['avg_loss'].iloc[i + window_length + 1] =(df['avg_loss'].iloc[i + window_length] * (window_length - 1) + df['loss'].iloc[i + window_length + 1])/window_length\n",
    "        df['rs'] = df['avg_gain'] / df['avg_loss']\n",
    "        df['rsi'] = 100 - (100 / (1.0 + df['rs']))\n",
    "    return df\n",
    "\n",
    "def post_Processing(df, cri):\n",
    "    df1 = df.drop(columns=['tic'])\n",
    "    df = df1.reset_index().dropna()\n",
    "    df = df.rename(columns={'yyyy':'year', 'mm':'month'})\n",
    "    cri1 = cri.merge(rsi_data, on=['year','month','tic'], how='inner')\n",
    "    return cri1\n",
    "def calculate_monthly_MACD(df):\n",
    "    k = df['Close'].ewm(span=12, adjust=False, min_periods=0).mean()\n",
    "    # Get the 12-day EMA of the closing price\n",
    "    d = df['Close'].ewm(span=26, adjust=False, min_periods=0).mean()\n",
    "    # Subtract the 26-day EMA from the 12-Day EMA to get the MACD\n",
    "    macd = k - d\n",
    "    # Get the 9-Day EMA of the MACD for the Trigger line\n",
    "    macd_s = macd.ewm(span=9, adjust=False, min_periods=0).mean()\n",
    "    # Calculate the difference between the MACD - Trigger for the Convergence/Divergence value\n",
    "    macd_h = macd - macd_s\n",
    "    # Add all of our new values for the MACD to the dataframe\n",
    "    df['macd'] = df.index.map(macd)\n",
    "    df['macd_h'] = df.index.map(macd_h)\n",
    "    df['macd_s'] = df.index.map(macd_s)\n",
    "    pd.set_option(\"display.max_columns\", None)\n",
    "    return df\n",
    "\n",
    "def calculate_sortino_ratio(df):\n",
    "    window = 12  # 12-month window\n",
    "    df['Returns'] = df['Adj Close'].pct_change()\n",
    "    df['Returns'].fillna(0, inplace=True)\n",
    "    def sortino_ratio(returns):\n",
    "        returns.apply(lambda x: 0 if x<0 else x )\n",
    "        downside_deviation = np.std(returns)\n",
    "\n",
    "        average_return = returns.mean()\n",
    "        sortino = (average_return ) / downside_deviation if downside_deviation != 0 else 0\n",
    "        return sortino\n",
    "\n",
    "    df['Rolling_Sortino'] = df['Returns'].rolling(window).apply(sortino_ratio)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Data-Pull for all Unique Tickers from the CRI Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_PV_data = pd.DataFrame()\n",
    "unique_Tickers = compustat_data_ALL['tic'].unique()\n",
    "for i in unique_Tickers:\n",
    "    try:\n",
    "        temp_df = download_data(i) \n",
    "        temp_df.reset_index(inplace=True)\n",
    "        temp_df['yyyy'] = temp_df.Date.apply(lambda x: x.year)\n",
    "        temp_df['mm'] = temp_df.Date.apply(lambda x: x.month)\n",
    "        temp_df.drop(['Date'],axis=1, inplace=True)\n",
    "        grouped = temp_df.groupby(by = ['yyyy','mm']).mean()\n",
    "        grouped.reset_index(inplace=True)\n",
    "        grouped['tic'] = i\n",
    "        company_PV_data = pd.concat([company_PV_data, grouped])\n",
    "    except Exception as e:\n",
    "        print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading in the values from YFinance data, which was aggregated monthly, then calculating the rolling mean of the volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas_gbq import read_gbq\n",
    "df = read_gbq(f\"\"\"\n",
    "SELECT *\n",
    "FROM capstone-402105.raw_data.yfinance_cleaned\n",
    "\"\"\",project_id='capstone-402105', dialect='standard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading:   0%|\u001b[32m                                                                                                                                                                                                                                                                               \u001b[0m|\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv(\"YFinance_data_cleaned.csv\")\n",
    "df['date'] = pd.to_datetime(df['yyyy'].astype(str) + df['mm'].astype(str), format='%Y%m')\n",
    "df.sort_values(by=['tic', 'date'], inplace=True)\n",
    "results = pd.DataFrame()\n",
    "for ticker, group in df.groupby('tic'):\n",
    "    rolling_window = group.rolling('365D', on='date')\n",
    "    group['rolling_mean'] = rolling_window['Volume'].mean()\n",
    "\n",
    "    results = pd.concat([results, group])\n",
    "\n",
    "results['1YearVolumeRatio'] = results['Volume']/results['rolling_mean']\n",
    "MACD_data = df.groupby('tic').apply(calculate_monthly_MACD)\n",
    "rsi_data = df.groupby('tic').apply(calculate_monthly_rsi)\n",
    "rsi_data1 = rsi_data.drop(columns=['tic'])\n",
    "rsi_data= rsi_data1.reset_index().dropna()\n",
    "result = df.groupby('tic').apply(calculate_sortino_ratio)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "MACD_data = MACD_data[['yyyy', 'mm', 'tic', 'macd', 'macd_h', 'macd_s']]\n",
    "rsi_data = rsi_data1[['yyyy', 'mm','tic','rsi']]\n",
    "result.reset_index(inplace=True)\n",
    "result = result[['yyyy', 'mm','tic','Rolling_Sortino']]\n",
    "MACD_data.drop(columns=['tic'], inplace=True)\n",
    "MACD_data.reset_index(inplace=True)\n",
    "final_df = result.merge(MACD_data, on = ['yyyy', 'mm', 'tic'], how = 'inner')\n",
    "final_df = final_df.merge(rsi_data,  on = ['yyyy', 'mm', 'tic'], how = 'inner')\n",
    "final_df = final_df[['tic', 'year', 'month', 'Rolling_Sortino', 'macd', 'macd_h', 'macd_s', 'rsi']]\n",
    "final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pushing the Data to BigQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from google.oauth2 import service_account\n",
    "import pandas_gbq as gbq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "credentials_path = '../token.json'\n",
    "\n",
    "# Authenticate with your credentials\n",
    "credentials = service_account.Credentials.from_service_account_file(\n",
    "    credentials_path, scopes=['https://www.googleapis.com/auth/bigquery'])\n",
    "\n",
    "# Set the credentials for pandas_gbq\n",
    "gbq.context.credentials = credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1663.75it/s]\n"
     ]
    }
   ],
   "source": [
    "import json \n",
    "from pandas_gbq import to_gbq\n",
    "with open('../token.json', 'r') as token_file:\n",
    "    token_data = json.load(token_file)\n",
    "    project_id = token_data.get('project_id', 'default-project-id')\n",
    "\n",
    "dataset_id = \"raw_data\"\n",
    "table_id = 'yfinance'\n",
    "\n",
    "to_gbq(yf_cleaned, destination_table=f'{project_id}.{dataset_id}.{table_id}', project_id=project_id, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4k/6rq2dc2j4w9fvhjkkjt2x0mr0000gn/T/ipykernel_65877/2709626079.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  final_df.dropna(inplace=True)\n"
     ]
    }
   ],
   "source": [
    "final_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 1430.53it/s]\n"
     ]
    }
   ],
   "source": [
    "import json \n",
    "from pandas_gbq import to_gbq\n",
    "with open('../token.json', 'r') as token_file:\n",
    "    token_data = json.load(token_file)\n",
    "    project_id = token_data.get('project_id', 'default-project-id')\n",
    "\n",
    "dataset_id = \"capstone\"\n",
    "table_id = 'yfinance_cleaned'\n",
    "\n",
    "to_gbq(final_df, destination_table=f'{project_id}.{dataset_id}.{table_id}', project_id=project_id, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
